

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>LLM推理加速新范式！推测解码（SpeculativeDecoding）最新综述 作者： AINLP 来源： AINLP 作者：hemingkx 合作单位：香港理工大学、北京大学、微软亚洲研究院、阿里巴巴 原文链接：https://zhuanlan.zhihu.com/p/678404136 好久不见！在这里跟大家分享我们最近关于推测解码（Specu  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">LLM推理加速新范式！推测解码（SpeculativeDecoding）最新综述</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              January 24, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuXhv9sFRVnthzZib2IawvhIYXeplDdFDkoBnLe6X4aJEjc9OuLXFZTZA/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： AINLP  来源： <a href="https://mp.weixin.qq.com/s/S5VrbhAdTIeyL1UviJEvLA">AINLP</a></p>
<h4 id="heading"></h4>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJuK8UUBxdZXj1c20hUg374YPgXibgDGytAy87YxvVk4WCRFWrdKJPshStrlPJp4vGEGUQodxt7ibOw/640?wx_fmt=jpeg" alt=""></p>
<p>作者：hemingkx</p>
<p><strong>合作单位：香港理工大学、北京大学、微软亚洲研究院、阿里巴巴</strong></p>
<p><strong>原文链接：https://zhuanlan.zhihu.com/p/678404136</strong></p>
<p>好久不见！在这里跟大家分享我们最近关于推测解码（Speculative Decoding）的一篇综述：</p>
<p><strong>Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding</strong></p>
<p>Abs: <a href="https://arxiv.org/abs/2401.07851">https://arxiv.org/abs/2401.07851</a></p>
<p>Repo: <a href="https://github.com/hemingkx/SpeculativeDecodingPapers">https://github.com/hemingkx/SpeculativeDecodingPapers</a></p>
<h4 id="1-background">1. Background</h4>
<p>近年来，随着LLM (Large Language Model) 规模的逐渐增大（200M-&gt;7B-&gt;175B），LLM的推理加速技术正逐步引起NLP学界的广泛关注。尤其是像ChatGPT[1]，Bard[2]这种线上实时交互的应用，LLM的inference latency（推理耗时）极大程度地影响了用户的使用体验。那么，LLM的Latency主要来自哪里呢？</p>
<p>相关研究表明，LLM推理主要是受内存带宽限制的（memory-bandwidth bound）[3][4]&ndash; LLM每个解码步所用的推理时间大部分并不是用于模型的前向计算，而是消耗在了将LLM巨量的参数从GPU显存（High-Bandwidth Memory，HBM）迁移到高速缓存（cache）上（以进行运算操作）。也就是说，LLM推理下的GPU并不是一个合格的打工人：他把每天大多数的时间都耗费在了早晚高峰堵车上，在公司没干啥实事儿（可不就是我摸鱼仙人:P）。</p>
<p>这个问题随着LLM规模的增大愈发严重。并且，如下左图所示，目前LLM常用的自回归解码（autoregressive decoding）在每个解码步只能生成一个token。这导致GPU计算资源利用率低下（-&gt;每个token的生成都需要重复读写LLM的巨量参数），并且序列的生成时间随着序列长度的增加而线性增加。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuTp1PmrMeQKKcI8rtzgEWoyfgBMo9H8xM9knZU51moEtIk90l5AOT3Q/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图1: 自回归解码（左），推测解码（右）</p>
<h4 id="2-speculative-decoding">2. Speculative Decoding</h4>
<p>那么，如何更好地利用GPU资源，让它成为一个合格的打工人呢？相信大家心里已经有答案了：把公司当作家，减少通勤次数，就可以少摸鱼多打工了（泪目）。</p>
<p>推测解码（Speculative Decoding），作为2023年新兴的一项LLM推理加速技术，正是提出了一种类似的解决方案：<strong>通过增加每个解码步LLM计算的并行性，减少总的解码步数（即减少了LLM参数的反复读写），从而实现推理加速</strong> 。</p>
<p>如上右图所示，在每个解码步，推测解码首先<strong>高效地“推测”</strong> target LLM（待加速的LLM）未来多个解码步可能生成的token，然后再用target LLM<strong>同时验证</strong> 这些token。通过验证的token作为当前解码步的解码结果。如果“推测”足够准确，推测解码就可以在单个解码步并行生成多个token，从而实现LLM推理加速。并且，使用target LLM的验证过程可以在理论上保证解码结果和target LLM自回归解码结果的完全一致[5][6]。</p>
<p>也就是说，<strong>推测解码在实现对target LLM推理加速的同时，不损失LLM的解码质量</strong> 。这种优异的性质导致推测解码受到了学界和工业界的广泛关注，从2023年初至今涌现了许多优秀的研究工作和工程项目（如Assisted Generation[7]，Medusa[8]，Lookahead Decoding[9]等等）。</p>
<p>考虑到推测解码领域2023年以来飞速的研究进展，我们撰写了一篇系统性的survey，给出推测解码的统一定义和通用算法，详细介绍了推测解码研究思路的演化，并对目前已有的研究工作进行了分类梳理。在下文中，我们将文章内容凝练为太长不看版——分享一些关于推测解码关键要素的看法，以及目前常用的研究思路，欢迎感兴趣的小伙伴一起讨论～</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuQEYQSyTDdn0lEt7vqLEL0AQrTicSVIDrOeyC1MhW625f0NYhicvsqdVg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图2: 推测解码研究思路的演化</p>
<h4 id="3-key-facets-of-speculative-decoding">3. Key Facets of Speculative Decoding</h4>
<p>首先，我们总结推测解码的定义：</p>
<blockquote>
<p>推测解码是一种“先推测后验证” (<em>Draft-then-Verify</em>) 的解码算法：在每个解码步，该算法首先<strong>高效地“推测”</strong> target LLM未来多个解码步的结果，然后用target LLM<strong>同时进行验证</strong> ，以加速推理。</p>
</blockquote>
<p>也就是说，所有符合在每个解码步“高效推测-&gt;并行验证“模式的推理算法，都可以称为是推测解码（或其变体）。<strong>推测解码实现加速的关键要素</strong> ，主要在于如下三点：</p>
<ul>
<li>相比于生成单一token，LLM并行计算额外引入的latency很小，甚至可以忽略；</li>
</ul>
<p>*<strong>“推测”的高效性&amp;准确性</strong> ：如何又快又准地“推测”LLM未来多个解码步的生成结果；</p>
<p>*<strong>“验证“策略的选择</strong> ：如何在确保质量的同时，让尽可能多的“推测”token通过验证，提高解码并行性。</p>
<p>如上文所述，LLM推理的主要latency瓶颈在于推理过程中参数的反复读写。在只考虑一个解码步的情况下，decoder-only LLM的forward latency主要和decoder层数有关——层数越深，推理时间越长。相比于这两者，LLM运算并行性带来的额外latency很小，这一点在非自回归解码的多个相关工作中有所讨论[10][11]。</p>
<p>因此，推测解码的算法设计主要考虑如下两点：“推测”（Drafting）的高效性和准确性，以及“验证“策略（Verification）的选择：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnurQnwK7bBAGkrLDoLCAVfHcgIMXDM2RxkCzk4WJ4ick21gWh7rw9xjjA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图3: 推测解码相关研究的归纳分类</p>
<h4 id="4-推测的高效性和准确性">4. “推测”的高效性和准确性</h4>
<blockquote>
<p>“推测“阶段（Drafting）的目的是精准地“预测”LLM未来多个解码步的生成结果，且不引入过多的latency。</p>
</blockquote>
<p>因此，“推测”阶段的设计聚焦在“推测精度（accuracy）”和“推测耗时（latency）“的权衡上。一般来说，用以推测的模型越大，推测精度越高（即通过验证的token越多），但是推测阶段的耗时越大。<strong>如何在这两者之间达到权衡，使得推测解码总的加速比较高，是推测阶段主要关注的问题。</strong></p>
<h4 id="41-independent-drafting">4.1 Independent Drafting</h4>
<p>最简单的Drafting思路是，拿一个跟target LLM同系列的smaller LM进行“推测”[12][13]。比如OPT-70B的加速可以用OPT-125M进行推测，T5-XXL可以用T5-small。这样的好处是可以直接利用现有的模型资源，无需进行额外的训练。而且，由于同系列的模型使用相近的模型结构、分词方法、训练语料和训练流程，小模型本身就存在一定的和target LLM之间的“行为相似性“（behavior alignment），适合用来作为高效的“推测“模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuWb56HsnjiaruA9VkegD7peXpPskt38iaes4MhsciasXSkAwictWOHicHgAg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图4: <a href="https://huggingface.co/blog/assisted-generation">https://huggingface.co/blog/assisted-generation</a></p>
<p>这一思路由Google和Deepmind同时提出[12][13]。作为Speculative Decoding的早期探索，这种“推测”思路易于实践和部署。并且，这两篇工作同时在理论上证明了推测解码不仅支持greedy decoding，还支持nucleus sampling的无损加速（我们下文会讲到）。这两种解码策略涵盖了LLM应用的大多数场景。因此，这两篇工作极大地促进推测解码在LLM推理加速中的应用，吸引了工业界和学术界的大量关注。</p>
<blockquote>
<p>然而，同系列小模型的“推测”精度还有提升空间吗？</p>
</blockquote>
<p>显然是有的。最直接的思路，就是去增强小模型和大模型之间的“行为相似性”（behavior alignment），让小模型模仿得“更像”一些。目前在这方面的研究进展集中在知识蒸馏（knowledge distillation）上：将target LLM作为教师模型，小模型作为学生模型，通过知识蒸馏让小模型更加趋向于target LLM的预测行为[14][15]。并且，知识蒸馏还可以有效地增强小模型的生成质量，通过减少低级的预测错误，增加通过验证的token数量。</p>
<h4 id="42-self-drafting">4.2 Self-Drafting</h4>
<p>然而，采用一个独立的“推测”模型也有缺点：</p>
<ul>
<li>
<p>首先，并不是所有的LLM都能找到现成的小模型，比如LLaMA-7B。重新训练一个小模型需要较多的额外投入。</p>
</li>
<li>
<p>另外，引入一个额外的小模型增加了推理过程的计算复杂度，尤其不利于分布式部署场景。</p>
</li>
</ul>
<p>因此，相关研究工作提出利用<strong>target LLM自己</strong> 进行“高效推测”。比如Blockwise Decoding[5]和Medusa[8]在target LLM最后一层decoder layer之上引入了多个额外的FFN Heads（如下所示），使得模型可以在每个解码步并行生成多个token，作为“推测”结果。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuXhv9sFRVnthzZib2IawvhIYXeplDdFDkoBnLe6X4aJEjc9OuLXFZTZA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图5: <a href="https://sites.google.com/view/medusa-llm">https://sites.google.com/view/medusa-llm</a></p>
<p>然而，这些FFN Heads依然需要进行额外的训练。除了这两个工作，还有一些研究提出利用Early-Existing或者Layer-Skipping来进行“高效推测“[16][17]，甚至仅仅是在模型输入的最后插入多个[PAD] token，从而实现并行的“推测”[18]。然而，“部署的便捷性”和“推测精度”之间依然存在一定的权衡关系。如何选择合适的“推测”策略，达到令人满意的加速效果，就见仁见智了。</p>
<blockquote>
<p>感兴趣的友友可以移步具体论文查看细节，我们后续也准备提供一个公平的加速评测，给大家提供一个参考～</p>
</blockquote>
<h4 id="5-验证策略的选择">5. 验证策略的选择</h4>
<blockquote>
<p>“验证“阶段（Verification）的首要目的是保证解码结果的质量。</p>
</blockquote>
<p>让我们重新回顾推测解码的验证过程：</p>
<p>如下图所示，在给定“草稿”（即推测结果）时，LLM的并行验证其实和训练阶段teacher-forcing的形式是一致的——在生成每个token时，都假设LLM的前缀输入是正确的。比如，在验证第三个“推测”token时，LLM以绿色前缀和两个黄色的&quot;推测“token作为前缀输入。以贪婪解码（greedy decoding）为例，以该前缀作为输入时，LLM会自己生成一个概率最大的token。如果这个token（绿色）和第三个“推测”token相同，就说明第三个“推测”token通过了“验证”——这个token本来就是LLM自己会生成的结果。</p>
<p>因此，第一个没有通过验证的“推测”token （图中的红色token）后续的“推测”token都将被丢弃。因为这个红色token不是LLM自己会生成的结果，那么前缀正确性假设就被打破，这些后续token的验证都无法保证前缀输入是“正确”的了。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuTp1PmrMeQKKcI8rtzgEWoyfgBMo9H8xM9knZU51moEtIk90l5AOT3Q/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图6：recap of Speculative Decoding</p>
<p>由此可见，推测解码是可以保证最终解码结果和target LLM原先的贪婪解码结果完全一致的。因此，贪婪解码经常被用于推测解码的demo展示[8]，用以清晰直观地表示推测解码在保持和target LLM解码结果等同的前提下，实现了数倍的推理加速。</p>
<blockquote>
<p>然而，严格要求和target LLM解码结果完全匹配（exact-match）是最好的策略吗？</p>
</blockquote>
<p>显然，并不是所有概率最大的token都是最合适的解码结果（比如beam search）。当推测模型的性能较好时，严格要求和target LLM结果匹配会导致大量高质量的“推测”token被丢弃，仅仅是因为它们和target LLM top-1解码结果不一致。这导致通过验证的“推测”token数量较小，从而影响推测解码的加速比。</p>
<p>因此，有一些工作提出可以适当地放松“验证”要求，使得更多高质量的“推测”token被接受，增大每个解码步通过验证的“推测”token数量，进一步提升加速比[12][14][15]。</p>
<p>除了支持贪婪解码，推测解码还可以在理论上保障和target LLM nucleus sampling的分布相同[12][13]，具体证明感兴趣的朋友可以查看相关paper～。另外，相比于只验证单一的“推测”序列，相关研究还提出可以让target LLM并行验证多条“推测”序列，从而进一步增大通过验证的“推测”token数量[19]。</p>
<h4 id="6-总结">6. 总结</h4>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/nW2ZPfuYqSLNUySD4drzcdC8Q64BEbnuHCVsBAibDia1gfsxJHmBHXuD4Upm7PcnhIiaOwVuvBPBaPOfDdlpathaQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>表1: 推测解码算法总结</p>
<p>在上表中，我们给出目前常用的推测解码算法的总结～。作为一种新兴的推理加速算法，推测解码在实现对target LLM推理加速的同时保障了解码结果的质量，具有广阔的应用前景和极大的科研潜力，个人比较看好～。然而，推测解码研究本身也存在许多尚未解答的问题，比如如何更好地实现target LLM和“推测”模型之间的行为对齐、如何结合具体任务的特点设计相应的推测解码策略（比如多模态模型加速），都是值得思考的问题。</p>
<h4 id="参考">参考</h4>
<ol>
<li>
<p><a href="https://chat.openai.com/">https://chat.openai.com/</a></p>
</li>
<li>
<p><a href="https://bard.google.com/">https://bard.google.com/</a></p>
</li>
<li>
<p>Latency lags bandwith <a href="https://dl.acm.org/doi/10.1145/1022594.1022596">https://dl.acm.org/doi/10.1145/1022594.1022596</a></p>
</li>
<li>
<p>Fast Transformer Decoding: One Write-Head is All You Need <a href="https://arxiv.org/abs/1911.02150">https://arxiv.org/abs/1911.02150</a></p>
</li>
<li>
<p>Blockwise Parallel Decoding for Deep Autoregressive Models <a href="https://arxiv.org/pdf/1811.03115.pdf">https://arxiv.org/pdf/1811.03115.pdf</a></p>
</li>
<li>
<p>Fast Inference from Transformers via Speculative Decoding <a href="https://arxiv.org/abs/2211.17192">https://arxiv.org/abs/2211.17192</a></p>
</li>
<li>
<p>Assisted Generation: a new direction toward low-latency text generation <a href="https://huggingface.co/blog/assisted-generation">https://huggingface.co/blog/assisted-generation</a></p>
</li>
<li>
<p>Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Heads <a href="https://github.com/FasterDecoding/Medusa">https://github.com/FasterDecoding/Medusa</a></p>
</li>
<li>
<p>Break the Sequential Dependency of LLM Inference Using Lookahead Decoding <a href="https://lmsys.org/blog/2023-11-21-lookahead-decoding/">https://lmsys.org/blog/2023-11-21-lookahead-decoding/</a></p>
</li>
<li>
<p>Non-Autoregressive Neural Machine Translation <a href="https://arxiv.org/abs/1711.02281">https://arxiv.org/abs/1711.02281</a></p>
</li>
<li>
<p>Glancing Transformer for Non-Autoregressive Neural Machine Translation <a href="https://arxiv.org/abs/2008.07905">https://arxiv.org/abs/2008.07905</a></p>
</li>
<li>
<p>Fast Inference from Transformers via Speculative Decoding <a href="https://arxiv.org/abs/2211.17192">https://arxiv.org/abs/2211.17192</a></p>
</li>
<li>
<p>Accelerating Large Language Model Decoding with Speculative Sampling <a href="https://arxiv.org/abs/2302.01318">https://arxiv.org/abs/2302.01318</a></p>
</li>
<li>
<p>Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation <a href="https://arxiv.org/abs/2203.16487">https://arxiv.org/abs/2203.16487</a></p>
</li>
<li>
<p>DistillSpec: Improving Speculative Decoding via Knowledge Distillation <a href="https://arxiv.org/abs/2310.08461">https://arxiv.org/abs/2310.08461</a></p>
</li>
<li>
<p>Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding <a href="https://arxiv.org/abs/2307.05908">https://arxiv.org/abs/2307.05908</a></p>
</li>
<li>
<p>Draft &amp; Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding <a href="https://arxiv.org/abs/2309.08168">https://arxiv.org/abs/2309.08168</a></p>
</li>
<li>
<p>Accelerating Transformer Inference for Translation via Parallel Decoding <a href="https://arxiv.org/abs/2305.10427">https://arxiv.org/abs/2305.10427</a></p>
</li>
<li>
<p>SpecInfer: Accelerating Generative Large Language Model Serving with Speculative Inference and Token Tree Verification <a href="https://arxiv.org/abs/2305.09781">https://arxiv.org/abs/2305.09781</a></p>
</li>
</ol>
<p><strong>进技术交流群请添加AINLP小助手微信（id: ainlp2)</strong></p>
<p><strong>请备注具体方向+所用到的相关技术点</strong></p>
<pre><code>![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJADkmZ2IX6Z23znAibuEevotDMq9iaMxiapK7jfMibiauGFkycicAJEs6x5U9SGyDJZ0S1tRed9TPNUUDQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p><strong>关于AINLP</strong></p>
<pre><code>AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括LLM、预训练模型、自动生成、文本摘要、智能问答、聊天机器人、机器翻译、知识图谱、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP小助手微信(id：ainlp2)，备注工作/研究方向+加群目的。

  


![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSKABHCqVVQkVYPrM4XY1vsd0iaeuXzyJnoFc8cibd5mYb4wdA3WMQtiaPVmr0XLZHMuVibqWncibpnTSnQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)**
</code></pre>
<p>更多AI工具，参考<a href="https://aibard123.com/">Github-AiBard123</a>，<a href="https://aibard123.com/">国内AiBard123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


