

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>完结篇！从0开始实现LLM：81、RAG代码实战(TinyRAGFlagEmbeddingQAnything讲解) 作者： AI科技解析 来源： AI科技解析 🌻🌻🌻 1、为什么要使用RAG？ 2、RAG是什么？ 3、怎么使用RAG？ akaihaoshuai，公众号：AI科技解析从0开始实现LLM：8、RAG（理论学习） 上一篇介绍了RAG的相关理论，这一篇通过代码进行  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">完结篇！从0开始实现LLM：81、RAG代码实战(TinyRAGFlagEmbeddingQAnything讲解)</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              April 28, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IiaVtahIhtNn1cyGQjOx0ktK6rFYUSFVRFSAxTbLf4pz5WIzMry5nziaA/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： AI科技解析  来源： <a href="https://mp.weixin.qq.com/s/uDE2788WVuvdIUJP7VENXg">AI科技解析</a></p>
<p>🌻🌻🌻</p>
<blockquote>
<ul>
<li>
<p>1、为什么要使用RAG？</p>
</li>
<li>
<p>2、RAG是什么？</p>
</li>
<li>
<p>3、怎么使用RAG？</p>
</li>
</ul>
</blockquote>
<p>akaihaoshuai，公众号：AI科技解析<a href="https://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484362&amp;idx=1&amp;sn=13851470c58fc2813a2032be35b8fb4e&amp;chksm=c2b89067f5cf197111f1675838f91fa54cc3df0316cc171ead5e84baf868f76683bc1ee29397&amp;token=1010206682&amp;lang=zh_CN#rd">从0开始实现LLM：8、RAG（理论学习）</a></p>
<p>上一篇介绍了RAG的相关理论，这一篇通过代码进行更深刻的理解。</p>
<p>TinyRAG</p>
<p>一个相对简单的RAG实现。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IOg5xuFz8icx2nmW1pmhpdPVQGp3wj5icNm0fVaFiaib2aliaT9VUUdr99iaA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>TinyRAG demo</p>
<p>其中VectorStore()为知识库创建过程，vector.query()为知识库查询过程，OpenAIChat()为生成回答过程。</p>
<h4 id="heading"></h4>
<p>创建知识库VectorStore()</p>
<p>整理本地文件到内存中。可以是加载文件，通过Embedding模型转换为文本向量。也可以直接加载已经通过Embedding转换后的文本向量（节省耗时）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I2RFL2JTNWPQ0Ln5NcflTSc6eaqtyAbE0tr6I1BFhZHaFET707oeKlw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>doc-&gt;特征向量</p>
<p>查询知识库（Retrieval）</p>
<p>对当前的文本特征和知识库的全部文本特征进行相似度查询，获取相似度最近的k个结果的对应文档。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I4QhBwMEnLSUYq0GlY7GDtkAW5bAajH9EDVdrGKHy7DXOSxZQCTjiahg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>比如当前的查询结果为：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IGIV3nfwaECu4POiaCdckpQHN2oCCcBzKiayhrUeXzye9004xeibMZsLlg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>LLM生成答案（Generation）</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IsHqiaicIvJ81sIiauSazgnDQNq0uUSgicKqc6wpZPwuZkkez2YuN78oXUQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>🌻小结</p>
<p>从上面代码中可以看出，Embedding模型是一个比较重要的点，模型的好坏直接影响了特征向量是否真正的表示了文本的含义。相似度的评价方法也很重要。</p>
<p>这里就引入一个问题？Embedding Model和LLM的Embedding都可以将文本转化为特征向量，他们有什么区别？？？</p>
<p>答：LLM的Embedding是在LLM中训练的，只是简单的查表处理，后面有transformer结构处理，最终生成回答。Embedding Model是专门为向量检索而训练的模型，有更加复杂的模型结构，可以将任意长度的输入文本输出为指定长度的特征。LLM的Embedding结果修改一下也可以用，但是得到的嵌入特征并不是最适合于做相似性计算的结果（肯定没专门用相似性loss监督训练出来的好）。</p>
<p>FlagEmbedding</p>
<p>如上面所说，🎈Embedding model是专门将任意输入文本信息转换为指定长度的特征向量，便于相似度检索的模型🎈。</p>
<p>FlagEmbedding中包含了Embedding的从预训练、微调到评测整套流程。</p>
<ol>
<li>
<p>拓展长上下文LLM训练方法：Activation Beacon</p>
</li>
<li>
<p>LM微调方法：LM-Cocktail</p>
</li>
<li>
<p>Embedding模型：Visualized-BGE, BGE-M3, LLM Embedder, BGE Embedding</p>
</li>
<li>
<p>Reranker模型：llm rerankers, BGE Reranker</p>
</li>
<li>
<p>评测标准：C-MTEB</p>
</li>
</ol>
<p>支持的Embedding模型：GitHub - FlagOpen/FlagEmbedding: Retrieval and Retrieval-augmented LLMs</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6Ispqicn2NCMia7E8AGZ7UJqKZw3ZsDOG0903qJaZRw51bG9uJjzdvYLmQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>下面具体介绍模型内容</p>
<p>Activation Beacon</p>
<h4 id="heading-1"></h4>
<p>《Soaring from 4K to 400K: Extending LLM&rsquo;s Context with Activation Beacon》</p>
<p>FlagEmbedding/Long_LLM/activation_beacon at master · FlagOpen/FlagEmbedding</p>
<p>Activation Beacon是作为一个插件模块引入的拓展LLM长上下文的微调方法。它完全保留了LLM在短上下文中的原始功能。它与滑动窗口一起工作，以流式处理长上下文，从而在训练和推理中具有竞争性的记忆和时间效率。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6ImS3oqZvEqlNPrB92qaS44Euu5DwVyrGrSYluB0CToDuwAZdsGiaL3rg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>它将LLM的原始激活（即键和值）压缩为高度紧凑的形式，对于长度为l的上下文，一组k（k &lt; l）个信标令牌被分派到它的末端，压缩比α（α = l/k）。使得LLM即使在有限的上下文窗口中也可以从广泛的上下文范围中感知信息。</p>
<p>为了有效地处理长上下文，我们提出了滑动窗口流处理。长上下文被划分为长度为l的多个区间。采用滑动窗口一次顺序处理一个间隔。当处理下一个间隔时，前一个间隔的原始激活被丢弃，而其浓缩的激活被累积。</p>
<blockquote>
<p>具体代码实现预计为：自定义CacheMemory，设定bacon_win_size，当cache_size超出bacon_win_size，reset cache缓存排布，新的cache添加到缓存中，旧的超出长度的cache部分进行压缩（超出1个长度，压缩为1，压缩比0%；超出10个token，压缩为1，压缩比90%；超出512个token，压缩比99%以上），当压缩的原始cache长度超过设定长度，可以重新开始新一组压缩。因此对于短上下文不进行压缩从而保持原始效果，长上下文通过检索压缩，提高推理效果。</p>
</blockquote>
<h4 id="heading-2"></h4>
<p>代码</p>
<p>在原始llamaconfig的基础上增加一些参数</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6Iv2DFmo8ItxqAGJ3d8KmDfpWlSG9q0RIDnwKISBiaHtIeichbaZvkbPYw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在LLaMAmodel处增加Memory类进行内存管理。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IxkIaREzRHf9NnLUAOnZsU8FlXqztmCpDNSzQqNXm4dalSW8eLKFmcA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在forward函数中增加</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IFQ5894sGElicjl7rQQ7VvR3ybHXKSOssps4hAlGBVHdY7n2jwjTnvTg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>训练过程大概为：将输入的长文本，保留最近的N个token，将先前的seq_len-N和token划分到长度为L的多个group中，增加额外的模块对每个group处理得到压缩后的token。通过将前面多个压缩token和最近的N个token拼接到一起生成回答，计算loss，更新模型权重（原始LLM模型权重冻结）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IaDrW2LVRrHn0uD3BnfxypE3APicGlu0XnqYzZT7SRP9WIDCBSjhgetg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>🌻小结</p>
<p>通过自定义cache缓存和额外增加模型结构，对超出预训练长度的长上下文进行压缩。可以认为是在斜A形的稀疏注意力基础上，对较靠前部分的token，不进行舍弃而是增加层进行压缩。提高长上下文推理速度，提升长上下文推理能力。若上下文长度较短，则不会进行token压缩，相比原始模型，推理速度会慢一些。不改变原始模型权重，插拔式拓展。</p>
<h4 id="heading-3"></h4>
<p>LM-Cocktail</p>
<p>《LM-Cocktail: Resilient Tuning of Language Models via Model Merging》</p>
<p>Yhyu13/LMCocktail-10.7B-v1 · Hugging Face</p>
<p>LM-Cocktail通过加权平均合并微调模型、预训练基础模型和来自其他领域的同行模型的参数，解决进行微调时可能出现的通用任务性能显著下降的问题。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IpNHDLaZb2RYKtkVtTyM7DbwBDTNQicyOQ8QnTQlibJwPaAerHPehLb5A/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>mix_models</p>
<p>按照权重合并模型参数。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IH6dFyB6ZETZlicicMnYbmv2SvTQHXk9fBh9ESdZ2OxPVcn6J5exicjiaVA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>merge_param</p>
<p>要求原始模型和微调模型的模型架构相同。</p>
<p>Embedding Model</p>
<h4 id="heading-4"></h4>
<p>BGE-M3</p>
<p>《BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation》</p>
<p>BAAI/bge-m3 · Hugging Face</p>
<p>BGE-M3是智源发布的一个Embedding model，支持100多种语言，它可以同时执行嵌入模型的三种常见检索功能：密集检索，多向量检索和稀疏检索。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IKnJ8YNo4kEPZesOJ84276Gqa4ymnkwqCJpRHbJv5SjY2orgvz7ic8fA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<blockquote>
<p>代码示例：FlagEmbedding/FlagEmbedding/BGE_M3/README.md at master · FlagOpen/FlagEmbedding</p>
</blockquote>
<p>它能够处理不同粒度的输入，从短句到长达8192个标记的长文档。它提出了一种新的自我知识蒸馏方法，其中不同的检索功能的相关性得分可以集成为教师信号，以提高训练质量。我们还优化了嵌入策略，实现了大批量和高训练吞吐量，以确保嵌入的区分度。M3-Embedding是第一个实现如此强大通用性的嵌入模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IM23M6gzCZEYibGoTM2a4T7IG14AMrM7Hg7icqmPrJj2pSTc4rK5VC2AQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>BGE-M3</p>
<p>模型结构为</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IswwzIiapQSu7TRT2kndf9enujGZTwrQJwyqNXIUibQNKcibU2oeaxRVxw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>使用的预训练数据集（194种语言、12亿个文本对、2655个跨语言对）和微调数据集如下所示。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6ITRAib6ATXTYp9LjicBapDQ0rARBvPiaACu34icMQFRdwD6ZHNw94iace1yg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Specification of training data.</p>
<p>预训练过程只进行稠密检索，微调阶段同时进行三种检索。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6Iib9G6pMZ388Avp822LF15ib6o9X8mibXkDrgVtaz9pZAZrVbGiaBVPy8og/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>推理检索阶段也会进行混合检索（多向量检索由于耗时较长，有时候会去掉），得到综合相似性得分。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IRXT7jIf3L8bg1afPUEV0bkJTzzSy9Gr7XlibjRZibqWCEN7XMC5bmA3A/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>模型训练目标为：期望{查询，正样本}的相似性得分比{查询，负样本}的相似性得分更高。则每种检索的loss函数均如下所示</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6ISZZgJrK1ExEyFZYxBqQUyV5CWyJBWFMkFbm7uVNRMjmhUBXB0uonjg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>其中 分别代表正样本和负样本。表示计算相似性的各种检索方法。</p>
<p>嵌入模型的训练质量可以受益于知识蒸馏，其利用了来自另一个排名模型的细粒度软标签。在这里，我们简单地使用积分分数 作为老师，其中每个检索方法的损失函数被修改为：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IxabFeDYOCJIkmAQs25OeUCTJFwuGIqC0rPJyeK0XMwDbtySa7qcgHw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>最终蒸馏的loss代码为</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IVJxDUwyLzWHiaYNMr2s3NZjb2Rqv3EvISEiaPeMPxrviar7wmZgV6cibyA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>loss</p>
<p>蒸馏的消融实验结果如下图所示，对于稀疏检索的影响较大。也表明密集和稀疏检索方法之间的不兼容性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6ItS3icsk4H2ibebgnxlRhicicJjMVGlDfBxXkQnqQ3ddpJw8TvqdFMmx5lA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>不同的微调策略影响，可以看出RetroMAE对微调效果提升较大。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IiaVtahIhtNn1cyGQjOx0ktK6rFYUSFVRFSAxTbLf4pz5WIzMry5nziaA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<ul>
<li>Efficient Batching</li>
</ul>
<p>为了解决不同序列之间长度变化较大，导致GPU利用率过低的问题。提前根据序列长度将数据分组，每次只在某一个长度段内随机采样数据，使得不同batch之间的数据长度相差较小，提高GPU利用效率。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6ITs9BavSJHHpyanGPhadzQe8cDnyckmWjEzTTcDIIKZnXESPLichJPvw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Efficient Batching</p>
<ul>
<li>MCLS Method</li>
</ul>
<p>由于缺少长文本数据或计算资源，提出了一种简单但有效的方法：MCLS（多CLS），而无需微调长文本。MCLS方法旨在利用多个CLS标记来联合捕获长文本的语义。具体来说，我们为每一个固定数量的标记插入一个CLS标记（在实验中，为每256个标记插入一个“[CLS]”），每个CLS标记可以从其相邻的标记中捕获语义信息。最终，通过平均所有CLS令牌的最后隐藏状态来获得最终的文本嵌入。</p>
<p>👑代码实战👑</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IAYl9RGu2ib7mGamzJ0943FibewSyBwPGeLuCXu5ohxoibFMKRPslnqH6w/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在model.encode()函数中，首先将文本通过tokenizer转换成token_id</p>
<pre><code>'What is BGE M3?'--&gt;[  101,  2054,  2003,  1038,  3351, 29061,  1029,   102]
</code></pre>
<p>然后输入模型进行处理。模型结构为</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I7tItLXiaibTdQibD3pYwKmHDKdWfoNQUibUbBvvbKiaq15uFGAVy7DMz37g/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>BGE模型</p>
<p>embedding层将[batch，seq_len]变为[batch，seq_len， 768]。然后输入BertEncoder处理，得到[batch，seq_len， 768]。最后通过Pool层输出pooled_output[batch， 768]（实际并未使用）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IhsXiabiaxo2uPOZKfa85diaU7I65CyBJQC5MB3XWg3pkLGm3B5yGMX2Eg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>BertPooler</p>
<p>得到last_hidden_state之后，获取稠密向量（有两种方式：取第一个特征 or 对所有特征进行平均）</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IibU8EduCHe70XC4LyczpTbHy4icuCaibkFhmAcVAf94Cgzau2TsTErGvw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>dense_embedding</p>
<p>实验测试，使用均值池化将会显着下降性能。</p>
<h4 id="heading-5"></h4>
<p>Visualized-BGE</p>
<p><a href="https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/visual">https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/visual</a></p>
<p>Visualized-BGE是一个多模态的Embedding模型，将图像标记嵌入集成到 BGE 文本嵌入框架中。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IpNea5WuEcHu9FO7jgS6Lj6srvMlZ5UP6P7GPK6dTmrwBFMmGnxPqIA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>文本使用的是bge模型，图像使用的Clip模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I7mCZPYkRPsfaCIrSJfNAfiaNDdenAt0yiazdu36ys84iabd98OBg4eIZQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在encode会根据输入情况选择不同的encoder</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IkpO4utMCMG9zEkqFNVubpiaZ00ztpicsFOuWwlZ3NkC6bbMYI3CJNyNA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>当输入图像+文本时，首先通过Clip模型将图像转换为img_token_emb，然后叠加位置编码</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IwX6Yhp7mbq4sF4bLkRNhZJ0LibqDZhib0XykIp01OXglzjtWibLqUoOLw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>然后对文本进行embedding处理</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I5KwTeVJAXCR86AiaCyzRKtPiaEgFZVHVDic16PewDtDfqvWx6Ctw47JEA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>将图像embedding和文本embedding连接，一起encoder处理</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IbLP9j0FWHibtZm2kib7M1VM1pM35XSxictCO0oPkNTwCjT3cXDFRx6sUQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>得到sequence_output输出结果。</p>
<h4 id="heading-6"></h4>
<p>OpenAI Embedding</p>
<p>嵌入（Embeddings） | OpenAI 官方帮助文档中文版</p>
<p>OpenAI 发布的嵌入模型</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IVUjhTbibkIEUumibRr4TEGdDbKDNYWiaCHf21f3UH8mDm9ufLEb8LayAg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<blockquote>
<p>测试效果可参考：- 派神 -：高级RAG(一)：Embedding模型的选择</p>
</blockquote>
<h4 id="heading-7"></h4>
<p>Voyage Embedding</p>
<p><a href="https://docs.voyageai.com/docs/embeddings">https://docs.voyageai.com/docs/embeddings</a></p>
<p>Voyage发布的一系列Embedding模型</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I5YHjKMz6UMAYpzkKXTia8LDImLaAbeSia3M1lUpbDM1mibezMf1HKVaYA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>示例代码如下GitHub - voyage-ai/voyageai-python: Voyage AI Official Python Library示例代码如下</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IZyLDq88yRz9SAZxh9wmM8aKib5JAjMibB986c6tMpf0g9jad2icGZVicpg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>或者：https://docs.llamaindex.ai/en/stable/examples/embeddings/voyageai/</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IcIZ5PxS1DuLqRktZrJHuqs5iaRjr95j9wmla47cAwXSYSP3oGCxJtkA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Reranker Model</p>
<p>与embedding模型不同，Reranker 模型输入query和doc，直接输出相似度而不是embedding特征。Reranker Model是基于交叉熵损失进行优化的，因此相关性得分不受特定范围的限制。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IroZnsH8epNGJDMWXOz8UIWDjC954R1XIgqB1E5ibmfI1QSoXgQDYe0A/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>也可以使用基于LLM训练过的Reranker Model</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I9iaRqnic0tPXPulhGIB7U0tISic47vziasIeyUs9eLV3WVZ3dicCzV4DlBA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>以bge-reranker-base为例，模型架构如下</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6I9NZHpFq353ibxLc1NtSK14yoApmrWex5gmcmib4jIlMIcQXicn6Q4vfkA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>bge-reranker-base</p>
<p>主要包含embedding编码、encoder处理，以及classifier生成相似度。</p>
<p>可以比较一下Embedding模型和Reranker模型的架构</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IGHPJT8nyFF0QaagneaXIMl4ctiaOmMEzbF9viaZ63MtUrY8rXoX4OEfQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Embedding vs Reranker</p>
<p>可以看出基本上只有最后不同。Embedding模型最后是一个pooler，得到一个特征向量（[bs, seq_len]-&gt;[bs, seq_len, 768]-&gt;[bs, 768]），一般是通过[bs, 0:1, 768]得到。</p>
<p>而Reranker模型最后是一个classifier，输出相似度得分（[bs, seq_len]-&gt;[bs, seq_len, 768]-&gt;[bs, 768]-&gt;[bs, 1]），通常是取[bs, 0:1, 768]通过nn.Linear层映射到[bs, 1]。</p>
<p>QAnything</p>
<p><a href="https://github.com/netease-youdao/QAnything">https://github.com/netease-youdao/QAnything</a></p>
<p>QAnything（Question andAnnswer based onAnything）是网易发布的一个本地知识库问答系统，可以选取本地存储的任意格式文件，并获得准确、快速和可靠的答案。目前支持的格式包括：PDF(pdf)、Word(docx)、PPT(pptx)、XLS(xlsx)、Markdown(md)、Email(eml)、TXT(txt)、Image(jpg，jpeg，png)、CSV (csv)、网页链接(html)和更多格式。</p>
<p>代码结构如下所示</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IrrNBEXicGqoULjFL0S9KW7L3CymW5R3J1FDvKHSPNpvdYmakBMqovzA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>QAnything</p>
<p>运行脚本</p>
<pre><code>bash scrips/run_for_local_option.sh
</code></pre>
<blockquote>
<p>喵喵喵夏夏：网易有道QAnything开源问答框架-部署文档</p>
</blockquote>
<p>BCEmbedding</p>
<p>BCEmbedding是网易发布的支持中英双语和交叉语言输入的Embedding和Reranker双模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6Id9JlJomqKurf1FpyR5EiaASibY4v5TJEHe89SKQiaZMqzYs6YwpiamdmCQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<blockquote>
<p>maidalun：为RAG而生-BCE embedding技术报告</p>
</blockquote>
<p>代码示例如下。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/h0vLdztmiam2eB5NbbvB124Ta7lGkzh6IaQQfx44tlezINjr7vwplJ3lgxZneZJkUiaa9ZslZAXcnjW8R0x1tQow/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>🌻总结</p>
<p>1、RAG过程包含：a)、文档整理成知识库；b)、对prompt查询知识库获取相关内容；c)、LLM生成回答。</p>
<p>2、从过程中可以看出，每个过程都可以不断的优化：文档的分段、不同数据格式的统一、大型数据库的查询效率、Embedding模型的选择、文本向量的相关性的评价方法、推理模型的选择等等。</p>
<p>3、FlagEmbedding中包含了Embedding的从预训练、微调到评测整套流程。</p>
<ul>
<li>
<p>拓展长上下文LLM训练方法：Activation Beacon</p>
</li>
<li>
<p>LM微调方法：LM-Cocktail</p>
</li>
<li>
<p>Embedding模型：Visualized-BGE, BGE-M3, LLM Embedder, BGE Embedding</p>
</li>
<li>
<p>Reranker模型：llm rerankers, BGE Reranker</p>
</li>
<li>
<p>评测标准：C-MTEB</p>
</li>
</ul>
<p>4、Activation Beacon通过自定义cache缓存和额外增加模型结构，对超出预训练长度的长上下文进行压缩。可以认为是在斜A形的稀疏注意力基础上，对较靠前部分的token，不进行舍弃而是增加层进行压缩。提高长上下文推理速度，提升长上下文推理能力。若上下文长度较短，则不会进行token压缩，相比原始模型，推理速度会慢一些。不改变原始模型权重，插拔式拓展。</p>
<p>5、LM-Cocktail将微调模型和预训练模型（相同模型架构）对参数进行加权合并，解决进行微调时可能出现的通用任务性能显著下降的问题。</p>
<p>6、Embedding Model是专门为向量检索而训练的一类模型，有更加复杂的模型结构，可以将任意长度的输入文本输出为指定长度的特征，能够更加准确的表示文本的含义。有BGE-M3、Visualized-BGE、OpenAI Embedding、Voyage Embedding、CohereAI Embedding (v2.0/ v3.0)和Jina Embeddings等。</p>
<p>7、BGE-M3是智源发布的一个Embedding model，支持100多种语言，它可以同时执行嵌入模型的三种常见检索功能：密集检索，多向量检索和稀疏检索。Visualized-BGE在BGE-M3基础上引入了Clip模型（处理图像），从而支持多模态处理的Embedding model。</p>
<p>8、Reranker Model是直接输出相似性得分的模型。与Embedding模型相比，就是在模型最后接了一个分类器，将输出特征[bs, 768]通过nn.Linear()映射到[bs, 1]（相似性得分）。</p>
<blockquote>
<p>因为余弦相似性不一定是评估相似性得分最好的方法，因此考虑直接通过模型输出相似度。</p>
</blockquote>
<p>9、Reranker Model可以用在Embedding Model后面，对前面召回的文档进行二次筛选。</p>
<blockquote>
<p>FlagEmbedding包含了Embedding模型和Reranker模型及其预训练和微调方法，并没有提到数据库和检索速度等相关内容。</p>
</blockquote>
<p>10、QAnything（Question andAnnswer based onAnything）是网易发布的一个本地知识库问答系统，可以选取本地存储的任意格式文件，并获得准确、快速和可靠的答案。</p>
<p>11、BCEmbedding是网易发布的支持中英双语和交叉语言输入的Embedding和Reranker双模型。Reranker Model可以对前一阶段得到的召回文档重新计算相似性得分，进行二次排序筛选。准确率稳定提升，数据越多，性能越好。</p>
<p>LLM系列文章：</p>
<p>***<a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247483992&amp;idx=1&amp;sn=e6ebdb90d26a2dc05b45b14a0d81d93d&amp;chksm=c2b891f5f5cf18e31d5f27c574bec80a205f2dd62ef78b90b2f96e6ebd5abba23ea4cbf3f0ec&amp;scene=21#wechat_redirect">从0开始实现LLM：1、大模型训练踩坑** </a></p>
<p>***<a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484054&amp;idx=1&amp;sn=38d64e255e4798cf11db2dc24eafc214&amp;chksm=c2b8913bf5cf182d1e6ba0147efce05f18194717f8b00cdd055a2d9cf34c5fda8ead3b74d157&amp;scene=21#wechat_redirect">从0开始实现LLM：2、大模型技术报告总结（GPT/PaLM/GLM/LLaMA/Skywork）** </a></p>
<p>*<strong><a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484083&amp;idx=1&amp;sn=a0fd9c60c53fa035a1189a3805c5a80f&amp;chksm=c2b8911ef5cf18088020c64b786d524ad0c2c03e364fee076fc471a5c069a03dc3f47f9f111d&amp;scene=21#wechat_redirect">从0开始实现LLM：3、大模型训练之数据扩展+deepspeed优化</a></strong></p>
<p>***<a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484144&amp;idx=1&amp;sn=3ca420ba6dcbf456788a06c1b304a793&amp;chksm=c2b8915df5cf184b912cf13aa169e0eb753994fdecfe3906284c9e3584b783b982f983c61a81&amp;scene=21#wechat_redirect">从0开始实现LLM：4、长上下文优化（持续更新中）** </a></p>
<p>***<a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484222&amp;idx=1&amp;sn=f447fc4556e984eae6fca18ec94387f5&amp;chksm=c2b89093f5cf1985521a9b11be3c1ba6651205ed85bd0d87d3d377ee8dce740068612a5d9f6f&amp;scene=21#wechat_redirect">从0开始实现LLM：5、长上下文优化（代码篇）YaRN/CLEX/LongLoRA/LM-Infinite/Streaming** </a></p>
<p>***<a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484297&amp;idx=1&amp;sn=c0d3e8293f1fd3877e134ba899754bcf&amp;chksm=c2b89024f5cf193237d5f3df13180801bc5e402c7c28075d916388b73efd7be051c9c912a815&amp;scene=21#wechat_redirect">从0开始实现LLM：6、模型量化理论+代码实战（LLM-QAT/GPTQ/BitNet 1.58Bits/OneBit）** </a></p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484336&amp;idx=1&amp;sn=a38516d993c5d509b654933905795e11&amp;chksm=c2b8901df5cf190b3d7fb85e1a8464497acf0ef7cdc780b81634cde4709b6550ef78a4cf3e0b&amp;scene=21#wechat_redirect">RLHF/PPO/DPO原理和代码简读</a></li>
</ul>
<p>***<a href="http://mp.weixin.qq.com/s?__biz=MzkzNDY1OTc3OA==&amp;mid=2247484362&amp;idx=1&amp;sn=13851470c58fc2813a2032be35b8fb4e&amp;chksm=c2b89067f5cf197111f1675838f91fa54cc3df0316cc171ead5e84baf868f76683bc1ee29397&amp;scene=21#wechat_redirect">从0开始实现LLM：8、RAG（理论学习）** </a></p>
<h4 id="heading-8"></h4>
<p><strong>参考文章</strong></p>
<ul>
<li>
<p>GitHub - KMnO4-zx/TinyRAG: TinyRAG</p>
</li>
<li>
<p><a href="https://github.com/ZBayes/basic_rag">https://github.com/ZBayes/basic_rag</a></p>
</li>
<li>
<p>GitHub - FlagOpen/FlagEmbedding: Dense Retrieval and Retrieval-augmented LLMs</p>
</li>
<li>
<p>BGE M3-Embedding 模型介绍</p>
</li>
<li>
<p>《RetroMAE v2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models》</p>
</li>
<li>
<p>《LM-Cocktail: Resilient Tuning of Language Models via Model Merging》</p>
</li>
<li>
<p>嵌入（Embeddings） | OpenAI 官方帮助文档中文版</p>
</li>
<li>
<ul>
<li>派神 -：高级RAG(一)：Embedding模型的选择</li>
</ul>
</li>
<li>
<p>maidalun：为RAG而生-BCE embedding技术报告</p>
</li>
<li>
<p><a href="https://github.com/netease-youdao/QAnything">https://github.com/netease-youdao/QAnything</a></p>
</li>
<li>
<p>喵喵喵夏夏：网易有道QAnything开源问答框架-部署文档</p>
</li>
<li>
<p><a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a></p>
</li>
<li>
<p>GitHub - run-llama/llama_index: LlamaIndex is a data framework for your LLM applications</p>
</li>
</ul>
<p>更多AI工具，参考<a href="https://aibard123.com/">Github-AiBard123</a>，<a href="https://aibard123.com/">国内AiBard123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


