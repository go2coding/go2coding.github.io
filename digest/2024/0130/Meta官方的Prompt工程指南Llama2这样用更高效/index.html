

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>Meta官方的Prompt工程指南：Llama2这样用更高效 作者： 机器之心 来源： 机器之心 机器之心报道**** 编辑：小舟 随着大型语言模型（LLM）技术日渐成熟，提示工程（Prompt Engineering）变得越来越重要。一些研究机构发布了 LLM 提示工程指南，包括微软、OpenAI 等等。 最近，Llama 系  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">Meta官方的Prompt工程指南：Llama2这样用更高效</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              January 30, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8d0Iib8tdrWKc6XpMQplfibelUD9pEBL8x0qZZ3uNaJbVPJaH2mBu08PMDhibWb9JOeL3sIp3HcCylw/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： 机器之心  来源： <a href="https://mp.weixin.qq.com/s/Xy8HdQih2d3lpNigCkOWIA">机器之心</a></p>
<p>机器之心报道****</p>
<p><strong>编辑：小舟</strong></p>
<p>随着大型语言模型（LLM）技术日渐成熟，提示工程（Prompt Engineering）变得越来越重要。一些研究机构发布了 LLM 提示工程指南，包括<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650876662&amp;idx=2&amp;sn=2638a860ab677edfb0bee19d38942413&amp;chksm=84e4ee88b393679e22698cc5acd413512c29743ed8c35bb48f20269f09ee9d254df32f35c03e&amp;scene=21#wechat_redirect">微软</a>、<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650900731&amp;idx=2&amp;sn=722e3ba47d25851637ec96a3db76102f&amp;chksm=84e44c85b393c593c221c419ef8d188cc7fc8a96fb98edb12be9c682c2b91bea03819122e983&amp;scene=21#wechat_redirect">OpenAI</a> 等等。</p>
<p>最近，Llama 系列开源模型的提出者 Meta 也针对 Llama 2 发布了一份交互式提示工程指南，涵盖了 Llama 2 的快速工程和最佳实践。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8d0Iib8tdrWKc6XpMQplfibeqRxs2QXJgUWChXOOSzliaWK4kxaL0kS2icUutWkyI1UIiaoDNdicA2c7XA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>以下是这份指南的核心内容。</p>
<p><strong>Llama 模型</strong></p>
<p>2023 年，Meta 推出了 Llama 、Llama 2 模型。较小的模型部署和运行成本较低，而更大的模型能力更强。</p>
<p>Llama 2 系列模型参数规模如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8d0Iib8tdrWKc6XpMQplfibemyNp7edX9E1VRJC6icjXRwvhbdDDpWZQHdbHVCx3WhmRv6bq6PlwCXA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Code Llama 是一个以代码为中心的 LLM，建立在 Llama 2 的基础上，也有各种参数规模和微调变体：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8d0Iib8tdrWKc6XpMQplfibelUD9pEBL8x0qZZ3uNaJbVPJaH2mBu08PMDhibWb9JOeL3sIp3HcCylw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>部署 LLM</strong></p>
<p>LLM 可以通过多种方式部署和访问，包括：</p>
<p>自托管（Self-hosting）：使用本地硬件来运行推理，例如使用 llama.cpp 在 Macbook Pro 上运行 Llama 2。优势：自托管最适合有隐私 / 安全需要的情况，或者您拥有足够的 GPU。</p>
<p>云托管：依靠云提供商来部署托管特定模型的实例，例如通过 AWS、Azure、GCP 等云提供商来运行 Llama 2。优势：云托管是最适合自定义模型及其运行时的方式。</p>
<p>托管 API：通过 API 直接调用 LLM。有许多公司提供 Llama 2 推理 API，包括 AWS Bedrock、Replicate、Anyscale、Together 等。优势：托管 API 是总体上最简单的选择。</p>
<p><strong>托管 API</strong></p>
<p>托管 API 通常有两个主要端点（endpoint）：</p>
<ol>
<li>
<p>completion：生成对给定 prompt 的响应。</p>
</li>
<li>
<p>chat_completion：生成消息列表中的下一条消息，为聊天机器人等用例提供更明确的指令和上下文。</p>
</li>
</ol>
<p><strong>token</strong></p>
<p>LLM 以称为 token 的块的形式来处理输入和输出，每个模型都有自己的 tokenization 方案。比如下面这句话：</p>
<blockquote>
<p>Our destiny is written in the stars.</p>
</blockquote>
<p>Llama 2 的 tokenization 为 [&ldquo;our&rdquo;, &ldquo;dest&rdquo;, &ldquo;iny&rdquo;, &ldquo;is&rdquo;, &ldquo;writing&rdquo;, &ldquo;in&rdquo;, &ldquo;the&rdquo;, &ldquo;stars&rdquo;]。考虑 API 定价和内部行为（例如超参数）时，token 显得尤为重要。每个模型都有一个 prompt 不能超过的最大上下文长度，Llama 2 是 4096 个 token，而 Code Llama 是 100K 个 token。</p>
<p><strong>Notebook 设置</strong></p>
<p>作为示例，我们使用 Replicate 调用 Llama 2 chat，并使用 LangChain 轻松设置 chat completion API。</p>
<p>首先安装先决条件：</p>
<ul>
<li></li>
</ul>
<pre><code>pip install langchain replicate
</code></pre>
<hr>
<pre><code>from typing import Dict, List
from langchain.llms import Replicate
from langchain.memory import ChatMessageHistory
from langchain.schema.messages import get_buffer_string
import os
# Get a free API key from https://replicate.com/account/api-tokens
os.environ [&quot;REPLICATE_API_TOKEN&quot;] = &quot;YOUR_KEY_HERE&quot;
LLAMA2_70B_CHAT = &quot;meta/llama-2-70b-chat:2d19859030ff705a87c746f7e96eea03aefb71f166725aee39692f1476566d48&quot;
LLAMA2_13B_CHAT = &quot;meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d&quot;
# We'll default to the smaller 13B model for speed; change to LLAMA2_70B_CHAT for more advanced (but slower) generations
DEFAULT_MODEL = LLAMA2_13B_CHAT
def completion (
prompt: str,
model: str = DEFAULT_MODEL,
temperature: float = 0.6,
top_p: float = 0.9,
) -&gt; str:
llm = Replicate (
model=model,
model_kwargs={&quot;temperature&quot;: temperature,&quot;top_p&quot;: top_p, &quot;max_new_tokens&quot;: 1000}
)
return llm (prompt)
def chat_completion (
messages: List [Dict],
model = DEFAULT_MODEL,
temperature: float = 0.6,
top_p: float = 0.9,
) -&gt; str:
history = ChatMessageHistory ()
for message in messages:
if message [&quot;role&quot;] == &quot;user&quot;:
history.add_user_message (message [&quot;content&quot;])
elif message [&quot;role&quot;] == &quot;assistant&quot;:
history.add_ai_message (message [&quot;content&quot;])
else:
raise Exception (&quot;Unknown role&quot;)
return completion (
get_buffer_string (
history.messages,
human_prefix=&quot;USER&quot;,
ai_prefix=&quot;ASSISTANT&quot;,
),
model,
temperature,
top_p,
)
def assistant (content: str):
return { &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: content }
def user (content: str):
return { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: content }
def complete_and_print (prompt: str, model: str = DEFAULT_MODEL):
print (f'==============\n {prompt}\n==============')
response = completion (prompt, model)
print (response, end='\n\n')
</code></pre>
<p><strong>Completion API</strong></p>
<ul>
<li></li>
</ul>
<pre><code>complete_and_print (&quot;The typical color of the sky is:&quot;)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>complete_and_print (&quot;which model version are you?&quot;)
</code></pre>
<p>Chat Completion 模型提供了与 LLM 互动的额外结构，将结构化消息对象数组而不是单个文本发送到 LLM。此消息列表为 LLM 提供了一些可以继续进行的「背景」或「历史」信息。</p>
<p>通常，每条消息都包含角色和内容：</p>
<p>具有系统角色的消息用于开发人员向 LLM 提供核心指令。</p>
<p>具有用户角色的消息通常是人工提供的消息。</p>
<p>具有助手角色的消息通常由 LLM 生成。</p>
<hr>
<pre><code>response = chat_completion (messages=[
user (&quot;My favorite color is blue.&quot;),
assistant (&quot;That's great to hear!&quot;),
user (&quot;What is my favorite color?&quot;),
])
print (response)
# &quot;Sure, I can help you with that! Your favorite color is blue.&quot;
</code></pre>
<p><strong>LLM 超参数</strong></p>
<p>LLM API 通常会采用影响输出的创造性和确定性的参数。在每一步中，LLM 都会生成 token 及其概率的列表。可能性最小的 token 会从列表中「剪切」（基于 top_p），然后从剩余候选者中随机（温度参数 temperature）选择一个 token。换句话说：top_p 控制生成中词汇的广度，温度控制词汇的随机性，温度参数 temperature 为 0 会产生几乎确定的结果。</p>
<hr>
<pre><code>def print_tuned_completion (temperature: float, top_p: float):
response = completion (&quot;Write a haiku about llamas&quot;, temperature=temperature, top_p=top_p)
print (f'[temperature: {temperature} | top_p: {top_p}]\n {response.strip ()}\n')
print_tuned_completion (0.01, 0.01)
print_tuned_completion (0.01, 0.01)
# These two generations are highly likely to be the same
print_tuned_completion (1.0, 1.0)
print_tuned_completion (1.0, 1.0)
# These two generations are highly likely to be different
</code></pre>
<p><strong>prompt 技巧</strong></p>
<p>详细、明确的指令会比开放式 prompt 产生更好的结果：</p>
<ul>
<li>
<ul>
<li></li>
</ul>
</li>
</ul>
<pre><code>complete_and_print (prompt=&quot;Describe quantum physics in one short sentence of no more than 12 words&quot;)
# Returns a succinct explanation of quantum physics that mentions particles and states existing simultaneously.
</code></pre>
<p>我们可以给定使用规则和限制，以给出明确的指令。</p>
<ul>
<li>
<p>风格化，例如：</p>
<ul>
<li>
<p>向我解释一下这一点，就像儿童教育网络节目中教授小学生一样；</p>
</li>
<li>
<p>我是一名软件工程师，使用大型语言模型进行摘要。用 250 字概括以下文字；</p>
</li>
<li>
<p>像私家侦探一样一步步追查案件，给出你的答案。</p>
</li>
</ul>
</li>
<li>
<p>格式化</p>
<ul>
<li>
<p>使用要点；</p>
</li>
<li>
<p>以 JSON 对象形式返回；</p>
</li>
<li>
<p>使用较少的技术术语并用于工作交流中。</p>
</li>
</ul>
</li>
<li>
<p>限制</p>
<ul>
<li>
<p>仅使用学术论文；</p>
</li>
<li>
<p>切勿提供 2020 年之前的来源；</p>
</li>
<li>
<p>如果你不知道答案，就说你不知道。</p>
</li>
</ul>
</li>
</ul>
<p>以下是给出明确指令的例子：</p>
<hr>
<pre><code>complete_and_print (&quot;Explain the latest advances in large language models to me.&quot;)
# More likely to cite sources from 2017
complete_and_print (&quot;Explain the latest advances in large language models to me. Always cite your sources. Never cite sources older than 2020.&quot;)
# Gives more specific advances and only cites sources from 2020
</code></pre>
<p><strong>零样本 prompting</strong></p>
<p>一些大型语言模型（例如 Llama 2）能够遵循指令并产生响应，而无需事先看过任务示例。没有示例的 prompting 称为「零样本 prompting（zero-shot prompting）」。例如：</p>
<hr>
<pre><code>complete_and_print (&quot;Text: This was the best movie I've ever seen! \n The sentiment of the text is:&quot;)
# Returns positive sentiment
complete_and_print (&quot;Text: The director was trying too hard. \n The sentiment of the text is:&quot;)
# Returns negative sentiment
</code></pre>
<p><strong>少样本 prompting</strong></p>
<p>添加所需输出的具体示例通常会产生更加准确、一致的输出。这种方法称为「少样本 prompting（few-shot prompting）」。例如：</p>
<hr>
<pre><code>def sentiment (text):
response = chat_completion (messages=[
user (&quot;You are a sentiment classifier. For each message, give the percentage of positive/netural/negative.&quot;),
user (&quot;I liked it&quot;),
assistant (&quot;70% positive 30% neutral 0% negative&quot;),
user (&quot;It could be better&quot;),
assistant (&quot;0% positive 50% neutral 50% negative&quot;),
user (&quot;It's fine&quot;),
assistant (&quot;25% positive 50% neutral 25% negative&quot;),
user (text),
])
return response
def print_sentiment (text):
print (f'INPUT: {text}')
print (sentiment (text))
print_sentiment (&quot;I thought it was okay&quot;)
# More likely to return a balanced mix of positive, neutral, and negative
print_sentiment (&quot;I loved it!&quot;)
# More likely to return 100% positive
print_sentiment (&quot;Terrible service 0/10&quot;)
# More likely to return 100% negative
</code></pre>
<p><strong>Role Prompting</strong></p>
<p>Llama 2 在指定角色时通常会给出更一致的响应，角色为 LLM 提供了所需答案类型的背景信息。</p>
<p>例如，让 Llama 2 对使用 PyTorch 的利弊问题创建更有针对性的技术回答：</p>
<hr>
<pre><code>complete_and_print (&quot;Explain the pros and cons of using PyTorch.&quot;)
# More likely to explain the pros and cons of PyTorch covers general areas like documentation, the PyTorch community, and mentions a steep learning curve
complete_and_print (&quot;Your role is a machine learning expert who gives highly technical advice to senior engineers who work with complicated datasets. Explain the pros and cons of using PyTorch.&quot;)
# Often results in more technical benefits and drawbacks that provide more technical details on how model layers
</code></pre>
<p><strong>思维链</strong></p>
<p>简单地添加一个「鼓励逐步思考」的短语可以显著提高大型语言模型执行复杂推理的能力（Wei et al. (2022)），这种方法称为 CoT 或思维链 prompting：</p>
<hr>
<pre><code>complete_and_print (&quot;Who lived longer Elvis Presley or Mozart?&quot;)
# Often gives incorrect answer of &quot;Mozart&quot;
complete_and_print (&quot;Who lived longer Elvis Presley or Mozart? Let's think through this carefully, step by step.&quot;)
# Gives the correct answer &quot;Elvis&quot;
</code></pre>
<p><strong>自洽性（Self-Consistency）</strong></p>
<p>LLM 是概率性的，因此即使使用思维链，一次生成也可能会产生不正确的结果。自洽性通过从多次生成中选择最常见的答案来提高准确性（以更高的计算成本为代价）：</p>
<hr>
<pre><code>import re
from statistics import mode
def gen_answer ():
response = completion (
&quot;John found that the average of 15 numbers is 40.&quot;
&quot;If 10 is added to each number then the mean of the numbers is?&quot;
&quot;Report the answer surrounded by three backticks, for example:```123```&quot;,
model = LLAMA2_70B_CHAT
)
match = re.search (r'```(\d+)```', response)
if match is None:
return None
return match.group (1)
answers = [gen_answer () for i in range (5)]
print (
f&quot;Answers: {answers}\n&quot;,
f&quot;Final answer: {mode (answers)}&quot;,
)
# Sample runs of Llama-2-70B (all correct):
# [50, 50, 750, 50, 50]  -&gt; 50
# [130, 10, 750, 50, 50] -&gt; 50
# [50, None, 10, 50, 50] -&gt; 50
</code></pre>
<p><strong>检索增强生成</strong></p>
<p>有时我们可能希望在应用程序中使用事实知识，那么可以从开箱即用（即仅使用模型权重）的大模型中提取常见事实：</p>
<ul>
<li>
<ul>
<li></li>
</ul>
</li>
</ul>
<pre><code>complete_and_print (&quot;What is the capital of the California?&quot;, model = LLAMA2_70B_CHAT)
# Gives the correct answer &quot;Sacramento&quot;
</code></pre>
<p>然而，LLM 往往无法可靠地检索更具体的事实或私人信息。模型要么声明它不知道，要么幻想出一个错误的答案：</p>
<hr>
<pre><code>complete_and_print (&quot;What was the temperature in Menlo Park on December 12th, 2023?&quot;)
# &quot;I'm just an AI, I don't have access to real-time weather data or historical weather records.&quot;
complete_and_print (&quot;What time is my dinner reservation on Saturday and what should I wear?&quot;)
# &quot;I'm not able to access your personal information [..] I can provide some general guidance&quot;
</code></pre>
<p>检索增强生成（RAG）是指在 prompt 中包含从外部数据库检索的信息（Lewis et al. (2020)）。RAG 是将事实纳入 LLM 应用的有效方法，并且比微调更经济实惠，微调可能成本高昂并对基础模型的功能产生负面影响。</p>
<hr>
<pre><code>MENLO_PARK_TEMPS = {
&quot;2023-12-11&quot;: &quot;52 degrees Fahrenheit&quot;,
&quot;2023-12-12&quot;: &quot;51 degrees Fahrenheit&quot;,
&quot;2023-12-13&quot;: &quot;51 degrees Fahrenheit&quot;,
}
def prompt_with_rag (retrived_info, question):
complete_and_print (
f&quot;Given the following information: '{retrived_info}', respond to: '{question}'&quot;
)
def ask_for_temperature (day):
temp_on_day = MENLO_PARK_TEMPS.get (day) or &quot;unknown temperature&quot;
prompt_with_rag (
f&quot;The temperature in Menlo Park was {temp_on_day} on {day}'&quot;,  # Retrieved fact
f&quot;What is the temperature in Menlo Park on {day}?&quot;,  # User question
)
ask_for_temperature (&quot;2023-12-12&quot;)
# &quot;Sure! The temperature in Menlo Park on 2023-12-12 was 51 degrees Fahrenheit.&quot;
ask_for_temperature (&quot;2023-07-18&quot;)
# &quot;I'm not able to provide the temperature in Menlo Park on 2023-07-18 as the information provided states that the temperature was unknown.&quot;
</code></pre>
<p><strong>程序辅助语言模型</strong></p>
<p>LLM 本质上不擅长执行计算，例如：</p>
<hr>
<pre><code>complete_and_print (&quot;&quot;&quot;
Calculate the answer to the following math problem:
((-5 + 93 * 4 - 0) * (4^4 + -7 + 0 * 5))
&quot;&quot;&quot;)
# Gives incorrect answers like 92448, 92648, 95463
</code></pre>
<p>Gao et al. (2022) 提出「程序辅助语言模型（Program-aided Language Models，PAL）」的概念。虽然 LLM 不擅长算术，但它们非常擅长代码生成。PAL 通过指示 LLM 编写代码来解决计算任务。</p>
<hr>
<pre><code>complete_and_print (
    &quot;&quot;&quot;
    # Python code to calculate: ((-5 + 93 * 4 - 0) * (4^4 + -7 + 0 * 5))
    &quot;&quot;&quot;,
model=&quot;meta/codellama-34b:67942fd0f55b66da802218a19a8f0e1d73095473674061a6ea19f2dc8c053152&quot;
)
</code></pre>
<hr>
<pre><code># The following code was generated by Code Llama 34B:
num1 = (-5 + 93 * 4 - 0)
num2 = (4**4 + -7 + 0 * 5)
answer = num1 * num2
print (answer)
</code></pre>
<p>原文链接：https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb?utm_source=twitter&amp;utm_medium=organic_social&amp;utm_campaign=llama&amp;utm_content=video</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9LSvGJnGeMgN5icZW9coZAvicwuFyhFM09n7QicLPKzKr3WHYGIdVvlVUA20KPvDWYDKFKvXlXMz5XA/640?wx_fmt=png" alt=""></p>
<p>© THE END</p>
<p>转载请联系本公众号获得授权</p>
<p>投稿或寻求报道：content@jiqizhixin.com</p>
<p>更多AI工具，参考<a href="https://aibard123.com/">Github-AiBard123</a>，<a href="https://aibard123.com/">国内AiBard123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


