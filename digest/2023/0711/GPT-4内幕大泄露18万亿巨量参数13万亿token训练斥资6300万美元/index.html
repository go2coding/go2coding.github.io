

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>GPT-4内幕大泄露！18万亿巨量参数，13万亿token训练，斥资6300万美元 作者： 新智元 来源： [新智元](https://mp.weixin.qq.com/s/iqvdcnwl4pR4jDXn57Yg8Q) ** ** **新智元报道 ** 编辑：编辑部 【新智元导读】 GPT-4又出业内爆料了！参数、架构、训练数据集、token、训  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">GPT-4内幕大泄露！18万亿巨量参数，13万亿token训练，斥资6300万美元</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              July 11, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpujXSMcAicEIr80uTZvicxx3WaN2sQ0cibAkm3k5qMiaYibamsLuO7wXLG9w/640?wx_fmt=png" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <pre><code>作者： 新智元  来源： [新智元](https://mp.weixin.qq.com/s/iqvdcnwl4pR4jDXn57Yg8Q)
</code></pre>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpibSXNKq9pGNmLxkfHFNked3giaX82je0IMumwqPBPYViaZSibHFlibhYKIg/640?wx_fmt=jpeg" alt=""></p>
<h4 id="heading"></h4>
<h4 id="heading-1"></h4>
<p>** ** **新智元报道 **</p>
<p>编辑：编辑部</p>
<h4 id="新智元导读-gpt-4又出业内爆料了参数架构训练数据集token训练和推理成本一次爆了个全而鉴于作者此前的战绩这份爆料确实具有一定的参考价值"><strong>【新智元导读】</strong> GPT-4又出业内爆料了！参数、架构、训练数据集、token、训练和推理成本……一次爆了个全。而鉴于作者此前的战绩，这份爆料确实具有一定的参考价值。</h4>
<p>就在刚刚，OpenAI的GPT-4又被业内人士「开源」了！</p>
<p>其中包括GPT-4的架构、训练和推理的基础设施、参数量、训练数据集、token数、成本、混合专家模型（Mixture of Experts，MoE）等非常具体的参数和信息。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wp6g19iasemYdicJZmV3L5wsC0UOwD5nJbZPe8JG0Ctkpy1ZvepQkpRYOw/640?wx_fmt=jpeg" alt=""></p>
<p>尤其是，在不同工程背后，OpenAI究竟是怎样权衡的。以及在巨型模型推理时，如何跨越其中最大的瓶颈。</p>
<p>如此重磅的爆料，出自何许人也？</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpAvkEhKXQ1lOb1p8ibLatHdFcs4AKOibuUT7pOI9wJFghO2QHBNBfqqEQ/640?wx_fmt=png" alt=""></p>
<p>文章作者，是SemiAnalysis的两位名叫Dylan Patel和Gerald Wong的撰稿人。</p>
<p>值得一提的是，此前曾在业内引起轩然大波的谷歌内部文件泄漏事件（「我们没有护城河，OpenAI也没有」），作者之一同样是Dylan Patel。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpoqsWHeXzuUfnL01Zep5Xz2Ij3gnR3TRibLu8UsouJPmjGtGwuW1Y87w/640?wx_fmt=png" alt=""></p>
<p>而DeepMind CEO Hassabis近日在外媒The Verge的采访中，确认了这份谷歌工程师泄漏文件的真实性。</p>
<p>可见，Dylan Patel的确有一些特殊渠道，这就让今日这份爆料的真实性又提高了几分。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wphv9dB9zKEGnDmiaZt9xLRf0FlmQ0LcTZMR8DdRFUIknUQDE9eRFLh6A/640?wx_fmt=jpeg" alt=""></p>
<p>出门问问CEO李志飞对此也发表了感言</p>
<p>很多企业都能做出GPT-4</p>
<h4 id="heading-2"></h4>
<p>在爆料文章作者看来，OpenAI之所以不open，不是为了确保人类不被AI毁灭，而是因为他们构建的东西是可复制的。</p>
<p>他甚至预计，未来所有中国和美国的互联网大厂或者AI头部初创企业，都会有能力构建出和GPT-4一样，甚至是超过GPT-4的模型。</p>
<p>但他同时也承认，GPT-4是OpenAI的伟大杰作。它凝结了工程师的匠心设计，复杂的构架和各种巧妙的工程上的取舍。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpG9lrvspMdSyfPmqIpSc7GOXAK97gCswrJtuuJeO7mjwaSe2UBy2fcA/640?wx_fmt=png" alt=""></p>
<p>而OpenAI最持久的护城河，是他们拥有真实用户的使用反馈，业内最顶尖的工程人才，以及先发优势带来的持续领先地位。</p>
<p>模型框架</p>
<h4 id="heading-3"></h4>
<p>首先爆料作者认为，GPT-4在120层中总共包含了1.8万亿参数，而GPT-3只有约1750亿个参数。</p>
<p>也就是说，GPT-4的规模是GPT-3的10倍以上。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpFhVl8XXKImg4ibnFQ2lgDoV0s0ty6wFyWPibrjQ6xWklKjDNiar8paPOw/640?wx_fmt=png" alt=""></p>
<p>此前网上流传的说法是，GPT-4的参数是1万亿，看来离实际情况还是低估了</p>
<p>为了保持合理的成本，OpenAI采用了MoE模型来进行构建。</p>
<p>具体而言，GPT-4拥有16个专家模型，每个MLP专家大约有1110亿个参数。其中，有两个专家模型被用于前向传播。</p>
<p>虽然文献中大量讨论了选择每个token指向哪些专家的高级算法，但是据说，OpenAI用于GPT-4的算法，其实非常简单。</p>
<p>此外，模型中还有大约550亿个参数，被用做注意力机制的共享。</p>
<p>在每次的前向传播推理（生成一个token）中，GPT-4只需要使用大约2800亿参数和560TFLOPs。</p>
<p>这与很多纯密集模型每次前向传播需要大约1.8万亿参数和3700TFLOPs形成了鲜明的对比。</p>
<p>数据集的构成</p>
<h4 id="heading-4"></h4>
<p>OpenAI用13万亿的token训出了GPT-4。</p>
<p>这个数据集不单单是包含了13万亿的token，而且因为没有高质量的token，这个数据集还包含了许多个epoch。</p>
<p>在Scale AI和数据集内部，还包含了数百万行的指令微调数据。</p>
<p>不过爆料作者说，在这些RLHF数据上，他们并没有找到太多信息。</p>
<p>在预训练阶段的上下文长度达到了8K（seqlen），而32k的版本是基于预训练后的8K版本微调而来的。</p>
<p>批大小在集群中是几天之内逐渐增加的，最终OpenAI使用的批大小为6000万。</p>
<p>当然，这「只是」每个750万token的专家模型的大小，因为不是每个专家模型都会看到全部的token。</p>
<p>并行策略</p>
<h4 id="heading-5"></h4>
<p>并行策略对于A100GPU是相当重要的。</p>
<p>OpenAI采用了8路张量并行，因为NVLink最高只支持这么多。</p>
<p>但除此之外，爆料作者听说OpenAI采用15路并行管线。</p>
<p>理论上，考虑到数据通信和计算时间，15个管线就有些多了。</p>
<p>但是因为受到内存容量的限制，这么多的管线就是有意义的了。</p>
<p>当纯管线和张量并行时，每个GPU的FP16参数大约是30GB。</p>
<p>但是一旦加上了KV缓存和成本，如果OpenAI使用的GPU大部分是40GB的A100，那这样的构架在理论上就是有意义的。</p>
<p>可能OpenAI使用的是ZeRo Stage 1，并且可能使用的是块级FSDP或者是混合共享数据并行。</p>
<p>为什么他们没有使用FSDP的全模型呢？可能是因为过高的通信成本。</p>
<p>虽然OpenAI大多数节点之间都有高速网络，但是没有覆盖所有的节点。</p>
<p>其中，至少有一些集群的连接带宽会比其他的集群低很多。</p>
<p>但是作者表示，他并不是太明白OpenAI在如此高的管线并行度下，如何避免在每批中产生如下图这样的「泡泡」（huge bubbles），很有可能OpenAI就是生生地抗下了这些成本。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpU6B0o63licuicoP1bDS0fOaEp8IQaWR3F4JDlPHe74dGXTbCuCDKAJDw/640?wx_fmt=png" alt=""></p>
<p>训练成本</p>
<h4 id="heading-6"></h4>
<p>OpenAI训练GPT-4的FLOPS约为2.15e25，在大约25000个A100上训练了90到100天，利用率在32%到36%之间。</p>
<p>这种极低的利用率，部分原因是故障数量过多，这就会导致需要重新从之前的检查点开始训练。比如上面提到的气泡成本。</p>
<p>这种情况浪费的训练成本极高。</p>
<p>另一个原因是这么多GPU之间的all-reduce非常昂贵。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpWNrSEnV9icgMOpgnLkfmiavlkhcWmvSkvkLKcctVuibMIxsDJkPRiaUFSA/640?wx_fmt=png" alt=""></p>
<p>此图表假设，无法融合每个操作、注意力机制所需的内存带宽、硬件开销相当于参数读取，都会导致效率低下。实际上，即使使用优化的库，比如英伟达的FasterTransformrmer库，总开销甚至还会更大</p>
<p>爆料作者怀疑，如果这种集群实际上是一群具有较弱网络连接的较小集群构成的，那么集群不同部分之间的非阻断（non-block）连接速度为800G/1.6T，但这些部分之间的连接速度仅为200G/400G。</p>
<p>如果OpenAI云计算的成本是差不多1美元/每A100小时的话，那么在这样的条件下，训练成本大约是6300万美元。</p>
<p>这还不包括所有的实验、失败的训练和其他成本，比如数据收集、RLHF、人力成本等。</p>
<p>如果考虑到刚刚说的这些因素，真实成本要高得多的多。</p>
<p>此外，这还得是在能别人买得到芯片/网络/数据中心，承担资本支出组建了这些系统，并将它们租给OpenAI的前提下。</p>
<p>但是放到今天，在2美元/每H100小时的条件下，预训练可以在大约8,192个H100上进行，只需要55天，费用为2150万美元。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpnL42aPR2k8VY7O87dgDndgmWPvcfNljG8S789FibqGcJeavpuQ3CPicA/640?wx_fmt=png" alt=""></p>
<p>上图显示了一些已公开的先进模型各自的参数数量和token。图中的线是谷歌DeepMind的Chinchilla缩放观测值（平滑了较大的误差条），线上的每一点都显示了使用该参数和token数训练模型所需的理论FLOPS</p>
<p>不过，爆料作者称到今年年底，至少将会有9个公司拥有超过上述大小的H100集群。</p>
<p>虽然并非所有这些公司都会将它们全部用于单个模型训练，但如果有公司这样做的话，他们将拥有比GPT-4更大的模型。</p>
<p>比如Meta到今年年底将拥有超过100,000个H100，但其中相当一部分将分布在自己的数据中心进行推理。</p>
<p>但是它最大的单个集群仍将超过25,000个H100。</p>
<p>总之，到今年年底，许多公司都会拥有足够的算力资源，来训练GPT-4大小的模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpujXSMcAicEIr80uTZvicxx3WaN2sQ0cibAkm3k5qMiaYibamsLuO7wXLG9w/640?wx_fmt=png" alt=""></p>
<p>本表是在英伟达A100上训练模型的理论最佳成本，没有考虑所需的人力、ML Ops工具、数据收集/预处理、故障恢复、one-shot/few-shot学习示例、推理等，许多部分的成本高得惊人</p>
<p>混合专家模型方面的权衡</p>
<h4 id="heading-7"></h4>
<p>MoE（混合专家模型）是一种在推理过程中减少参数量的很好方法，虽然同时会增加参数量。</p>
<p>但是这对于每个训练标记来编码更多信息是必要的，因为获取足够高质量的标记非常困难。</p>
<p>如果OpenAI真的想追求最佳性能，他们需要训练两倍的token才能达到。</p>
<p>话虽如此，OpenAI还是做出了不少的取舍。</p>
<p>例如，在推理过程中处理MoE非常困难，因为模型的每个部分并不在每个token生成时都被使用。</p>
<p>这意味着有些部分可能处于休眠状态，而其他部分在工作。</p>
<p>当为用户提供服务时，这种情况会大大降低利用率。</p>
<p>研究人员已经证明，使用64-128个专家模型比使用16个专家模型能够获得更好的损失情况，但这仅仅是研究结果。</p>
<p>采用相对比较少的专家模型的原因很多，OpenAI选择16个专家的原因之一是因为在许多任务上更多的专家模型很难泛化。</p>
<p>使用更多的专家模型也更难实现收敛。</p>
<p>在如此庞大的训练过程中，OpenAI选择在专家模型数量上反而更为保守。</p>
<p>此外，使用较少的专家模型还有助于他们的推理基础架构。在切换到混合专家模型推理架构时，存在各种困难的取舍和权衡。</p>
<p>爆料作者从对LLM推理的基本取舍开始讨论，然后再讨论OpenAI面临的问题和他们所做的选择。</p>
<p>推理权衡</p>
<h4 id="heading-8"></h4>
<p>在介绍推理权衡之前，顺带提一下，爆料者与所有的LLM公司交谈过后，发现英伟达的FasterTransformer推理库非常糟糕，TensorRT更是如此。</p>
<p>这意味着，如果英伟达不修改，人们还需要从头开始创建自己的解决方案。</p>
<p>推理大型语言模型有三个主要的权衡，即批大小（同时处理用户数）维度和使用的芯片数量，具体如下：</p>
<p><strong>1. 延迟</strong></p>
<p>模型必须在合理的延迟时间内做出响应。谁也不想在聊天APP中等待几秒钟才开始收到输出。预填（输入token）和解码（输出token）的处理时间各不相同。</p>
<p><strong>2. 吞吐量</strong></p>
<p>模型必须以每秒输出一定数量的token。人类大约需要每秒30个token。对于其他各种用例，较低和较高的吞吐量都可以接受。</p>
<p><strong>3. 利用率</strong></p>
<p>运行模型的硬件必须实现高利用率，否则成本过高。虽然更高的延迟和较低的吞吐量，可以用来将更多用户请求组合在一起，从而实现更高的利用率，但也会增加难度。</p>
<p>LLM推理的关键是平衡内存带宽和计算这两个要点。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpVmibGLXVJll66WNfctQDhgPzVhcTRSum4ANKENSz45p59hpEEEx5sXw/640?wx_fmt=png" alt=""></p>
<p>LLM理论带宽要求：经假设可得出，在iPhone 14上可跑的最大模型大小为~10亿个FP16参数，或~40亿个int4参数，这是基于智能手机的LLM的基本限制，任何更大的模型会无法被采用</p>
<p>简单来讲，每个参数都必须被读取，并且与之相关的有2个FLOP。</p>
<p>因此，大多数芯片的比率（H100 SXM仅有3TB/s内存带宽，但FP8有2,000 TFLOP/s）在批大小为1的推理中完全是不平衡的。</p>
<p>如果只有一个用户（批大小为1），那么在每次生成token时，为了读取每个参数所需的内存带宽，会主要占据推理时间，而计算时间几乎可以忽略不计。</p>
<p>为了将大型语言模型高效地扩展到多个用户，批处理大小必须超过1。多个用户将参数读取成本分摊。例如，在批大小为256/512时，每个字节的内存读取可以获得512 FLOP/s或1024 FLOP/s。</p>
<p>这个比率更接近H100的内存带宽与FLOPS之间的平衡。这有助于实现更高的利用率，但代价是更高的延迟。</p>
<p>很多人认为内存容量是LLM推理的一个主要瓶颈，因为大型模型需要多个芯片进行推理，而较高的内存容量意味着它们可以适应较少的芯片。</p>
<p>然而，实际上更好的方法是使用更多的芯片，以便将延迟降低，增加吞吐量，并且可以使用更大的批大小以实现更高的利用率。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpp9cCKqxVuMIHGibe1SIPlhGC0tXic9MLJX3RgyNQ6nXMiaYRjL4mPPo6A/640?wx_fmt=png" alt=""></p>
<p>GPT-4推理权衡和基础设施</p>
<h4 id="heading-9"></h4>
<p>以上所提到的，对GPT-4推理来说非常困难。但是作为一个MoE模型，再次引入了一系列全新的困难。</p>
<p>每个生成token的前向传递可以路由到不同的专家组。这对在较大的批大小下的吞吐量、延迟和利用率之间的权衡造成了困扰。</p>
<p>OpenAI的GPT-4有16个专家，每个前向传递路由到其中2个专家。</p>
<p>这意味着如果批大小为8，每个专家的参数读取可能只有批大小为1。</p>
<p>更糟糕的是，这可能意味着一个专家的批大小为8，而其他专家的批大小为4、1或0。</p>
<p>每个生成token，路由算法都会将前向传递发送到不同的方向，导致token之间的延迟和专家批大小显著变化。</p>
<p>推理基础设施是OpenAI选择较少数量的专家的主要原因之一。如果他们选择更多的专家，内存带宽会成为推理的瓶颈。</p>
<p>OpenAI的推理集群通常可以达到4k+的批大小，这意味着即使在专家之间实现最佳的load平衡，专家的批大小也只有大约500左右。这需要非常大量的使用才能实现。</p>
<p>爆料者称，我们了解到OpenAI在一个由128个GPU组成的集群上进行推理。他们在多个数据中心和地理位置上都有多个这样的集群。</p>
<p>推理采用8路张量并行和16路管线并行。每个由8个GPU组成的节点只有约130B的参数，或者在FP16下每个GPU不到30GB，在FP8/int8下不到15GB。</p>
<p>这样可以在40GB的A100上运行推理，只要所有批的KV缓存大小不会过大。</p>
<p>不同节点上的包含不同专家的层不会被分割，因为那样会导致网络流量过于不规则，而在每个生成token之间重新计算KV缓存的代价太高。</p>
<p>对于未来的MoE模型扩展和条件路由，最大的困难是如何处理KV缓存的路由。</p>
<p>模型的层数为120，所以可以简单地将它们分配给15个不同的节点，但是因为第一个节点需要进行数据加载和嵌入，所以在推理集群的主节点上放置较少的层是有意义的。</p>
<p>此外，有一些关于「推测解码」（后续）的传闻，这也解释了为什么主节点需要包含较少的层。</p>
<p>推理成本</p>
<h4 id="heading-10"></h4>
<p>与拥有1750亿参数的Davinchi模型相比，GPT-4的成本是其3倍，尽管其前馈参数只增加了1.6倍。</p>
<p>这主要是因为GPT-4需要更大的集群，并且实现的利用率更低。</p>
<p>作者认为，在128个A100上推理GPT-4的8k序列长度每1,000个标记的成本为0.0049美元，而在128个H100上推理GPT-4的8k序列长度每1,000个标记的成本为0.0021美元。</p>
<p>需要注意的是，这是假设有相当高的利用率，并保持较高批大小的情况下。</p>
<p>但很明显，OpenAI有时的利用率非常低。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpicxHnrmK1UOAwia33hJONlpsp0B8ca91VXdsdoFbnScj2MlanpWaQMNA/640?wx_fmt=png" alt=""></p>
<p>对此作者假设，OpenAI会在低峰时段关闭集群，重新配置节点，恢复训练较小的测试模型，并尝试各种新技术，从而降低推理成本。</p>
<p>如果OpenAI不这样做，他们的利用率会更低，而成本也将增加一倍以上。</p>
<p>多查询注意力</p>
<h4 id="heading-11"></h4>
<p>除此之外，OpenAI也在使用多查询注意力（Multi-Query Attention，MQA）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpNpkegCobfeHDjK1fjoIZq1Iic9ltmRJiaMvPgamYF7qicBw9Qt0ujfAcw/640?wx_fmt=png" alt=""></p>
<p>论文地址：https://arxiv.org/pdf/1911.02150.pdf</p>
<p>简而言之，只需要一个注意力头，并且可以显著减少KV缓存的内存占用。</p>
<p>即便如此，32k长度的GPT-4肯定无法在40GB的A100上运行，而8k的最大批大小也有上限。</p>
<p>连续批处理</p>
<h4 id="heading-12"></h4>
<p>OpenAI实现了可变批大小和连续批处理。</p>
<p>这样做可以允许一定程度的最大延迟，并优化推理成本。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpGHjiaiapzOddlqc7TLHjk23zI57dKMUI1T6CbmshXiaKEcMicxzrZ5lJPg/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpFGyMoAvQbAiarmObmcpSnic2D7IU2HGBx4d1OnicryKXDADHgUOv43Cag/640?wx_fmt=png" alt=""></p>
<p>推测解码（Speculative Decoding）</p>
<h4 id="heading-13"></h4>
<p>爆料称，OpenAI在GPT-4的推理过程中使用了「推测解码」，这其中还有100%的不确定性。</p>
<p>token到token的延迟变化，以及在进行简单的检索任务和更复杂的任务时差异，似乎表明这一点是可能的，不过还是有太多的变量无法确定。</p>
<p>在此，爆料者通过DeepMind的一项研究「Accelerating LLM Inference with Staged Speculative Decoding」中的文本，进行了适当修改/添加一些细节，进行了解释。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpROicrCsStNbZNceQID4jOAK1A06MCMUIHvIR0rY0w86BjBuELQAzOpg/640?wx_fmt=png" alt=""></p>
<p>使用LLM通常分为两个阶段。</p>
<p>首先是预填充（prefill），将提示文本输入模型中以生成KV缓存和第一个输出的对数几率（可能的token输出的概率分布）。这个过程通常很快，因为整个提示文本可以并行处理。</p>
<p>第二个阶段是解码（decoding）。从输出的对数几率中选择一个token，并将其反馈到模型中，模型将生成下一个token的对数几率。重复这个过程，直到生成所需数量的token。</p>
<p>由于解码必须按顺序进行，每次都需要将权重流通过计算单元以生成单个token。因此当以小量批运行时，这个第二阶段的计算密集度（即计算FLOP/内存带宽的字节数）非常低。因此，解码通常是自回归生成中最昂贵的部分。</p>
<p>这就是为什么OpenAI的API调用中，输入token比输出token便宜得多的原因。</p>
<p>「推测解码」的基本思想是使用一个更小、更快的草案模型提前解码多个token，然后将它们作为一个批输入到预测模型中。</p>
<p>如果草案模型的预测是正确的，即更大的模型也同意这些预测，那么可以使用单个批解码多个token，这样可以节省大量的内存带宽和时间。</p>
<p>然而，如果更大的模型拒绝了草案模型预测的token，则剩余的批将被丢弃，算法自然会恢复到标准的逐个token解码。</p>
<p>「推测解码」可能还伴随着拒绝抽样的方案，以从原始分布中进行采样。值得注意的是，这仅在带宽是瓶颈的小批设置中有用。</p>
<p>「推测解码」以计算换取带宽，而成为一个有吸引力的性能工程目标有两个关键原因：</p>
<p>首先，它不会降低模型质量。其次，它提供的性能改进通常与其他方法正交，因为其性能来自于将「顺序执行」转换为「并行执行」。</p>
<p>当前的推测方法为批预测的单独序列。然而，这种方法不能很好地拓展到大量的批，或低草案模型对齐上。</p>
<p>直观地说，两个模型在连续长序列的token上达成一致的概率呈指数级低，这意味着随着算术密度的增加，推测解码的收益会迅速减少。</p>
<p>爆料者认为，如果OpenAI使用「推测解码」，他们可能只在大约4个token的序列中使用。</p>
<p>顺便提一句，有关OpenAI阉割，而导致GPT-4质量降低的整个阴谋，可能只是因为他们让预测模型接受了「推测解码」模型的低概率序列。</p>
<p>另外有人推测，Bard也使用了「推测解码」，因为谷歌在将整个序列发送给用户之前会等待其完全生成，但在爆料者认为，这种猜测是完全不正确的。</p>
<p>视觉多模态</p>
<h4 id="heading-14"></h4>
<h4 id="heading-15"></h4>
<p>视觉多模态能力是GPT-4中最不令人印象深刻的部分，至少与领先的研究相比是如此。</p>
<p>当然，现在还没有人将多模态LLM的研究成果商业化。</p>
<p>爆料者称，它是一个独于文本编码器的视觉编码器，还有交叉注意力，架构类似于Flamingo，并在GPT-4 1.8T上增加了更多参数。</p>
<p>GPT-4多模态能力是在文本预训练之后，又用大约2万亿token进⾏了微调。</p>
<p>据称，在视觉模型上，OpenAI原本希望从头开始训练，但因其不够成熟，无奈从文本训练模型进行微调。</p>
<p>而下一代模型GPT-5，其训练应该从零开始训练视觉模型，并且能够生成图像，甚至生成音频。</p>
<p>这样的视觉能力主要目的之一，让自主智能体能够阅读网页，并转录图像，视频中的内容。</p>
<p>值得一提的是，OpenAI用来训练多模态模型的数据包括：「联合数据」（LaTeX/文本）、网页屏幕截图、YouTube视频（采样帧，以及运行Whisper获取字幕）。</p>
<p>关于LLM的过度优化，一个有趣的事实是视觉模型的IO成本不同于文本模型。在视觉模型中，数据加载IO大约是文本模型的150倍。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb1iaa9cbPNdX4znfk1glR9wpWDhM0usepgxvMdfkfMj8sl3BAUXkHbwMXMV8Dqfg2ibvqpKQBDIG2yg/640?wx_fmt=png" alt=""></p>
<p>视觉模型的IO成本很低</p>
<p>视觉模型中的每个token 600字节，文本是4字节/token。</p>
<p>因此这需要在图像压缩方面做很多工作。这对于硬件供应商来说极为重要，因为他们正在围绕LLM的用例和比率优化2-3年后的硬件。</p>
<p>他们可能会发现自己身处的世界中，每个模型都具有强大的视觉和音频功能。</p>
<p>他们可能会发现自己的架构适应性会很差。</p>
<p>总的来说，架构肯定会超越我们今天看到的基于文本简化的密集模型，和MoE模型。</p>
<p>参考资料：</p>
<p><a href="https://www.semianalysis.com/p/gpt-4-architecture-infrastructure">https://www.semianalysis.com/p/gpt-4-architecture-infrastructure</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb1lKYCMMiaxGxWTbkaPTAxuR84iaPsp8u8Yg0okpLUj3ibsPkwdQXjibPcp8oW1jmJAmZmMEia2sjDKpGA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_gif/UicQ7HgWiaUb10PoMc8QQNrjsp8lOMiaPwVkHbjVicxntJynwdmjiadosl2znIvDTSjWsp4kcqlbqVdFt6TxqpptrkA/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


