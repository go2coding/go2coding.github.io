

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>一夜之间，大模型格局大变天！！ 作者： DASOU 来源： DASOU **点击这里加入DASOU学习圈** 一夜之间，大模型格局再次发生巨变。 今日，Meta 终于发布了大家期待已久的免费可商用版本 Llama 2。 Llama 2论文报告在后台回复【 0301 】获取论文合集 一直以来 Llama 可以说是 AI 社区内最强大的开源大模型。但因为开源  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">一夜之间，大模型格局大变天！！</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              July 19, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhhlsvoSgjUVP72jTMU15eU1t9kFfj2R9ueoEfjI5dh9TVHknVg9Efkg/640?wx_fmt=png" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： DASOU  来源： <a href="https://mp.weixin.qq.com/s/qrFpHnJuqQDnNRLb3BIMCQ">DASOU</a></p>
<p>**<a href="http://mp.weixin.qq.com/s?__biz=MzIyNTY1MDUwNQ==&amp;mid=2247493502&amp;idx=1&amp;sn=e479a8c0c8fd4c40aa51e055ebc69aa8&amp;chksm=e87ed558df095c4e7e85ef6f378996a314257ac5f4caebfd8b79a15636dc131ee047cbf7f91e&amp;scene=21#wechat_redirect">点击这里加入DASOU学习圈** </a></p>
<p>一夜之间，大模型格局再次发生巨变。</p>
<p><strong>今日，Meta 终于发布了大家期待已久的免费可商用版本 Llama 2。</strong></p>
<p><strong>Llama 2论文报告在后台回复【</strong> <strong>0301</strong> <strong>】获取论文合集</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhE50gu84vjhXNIF48SWjibFAARzvrUSQPr4DArx9HDUXkLGxXOC0My7g/640?wx_fmt=png" alt=""></p>
<p>一直以来 Llama 可以说是 AI 社区内最强大的开源大模型。但因为开源协议问题，一直不可免费商用。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhuwspQ4cIhEhK2MMleq8xsGnnbVOJWTm6FtiaRATeq97T9YSRbZxGkcA/640?wx_fmt=png" alt=""></p>
<p>此次 Meta 发布的 <strong>Llama 2 模型系列包含 70 亿、130 亿和 700 亿三种参数变体</strong> 。此外还训练了 340 亿参数变体，但并没有发布，只在技术报告中提到了。</p>
<p>据介绍，<strong>相比于 Llama 1，Llama 2 的训练数据多了 40%，上下文长度也翻倍，并采用了分组查询注意力机制</strong> 。具体来说，Llama 2 预训练模型是在 <strong>2 万亿的 token</strong>  上训练的，精调 Chat 模型是在 <strong>100 万人类标记数据上训练</strong> 的。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhsxIbN41v9NiahYkBtuNZm28n03nMtHmvibNlYvic1ECUWpNT5gP7bbWNg/640?wx_fmt=png" alt=""></p>
<p>公布的测评结果显示，Llama 2 在包括推理、编码、精通性和知识测试等许多外部基准测试中都优于其他开源语言模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qhzlhwiaia7DN2FYK1K9ScG5ZxXdWyuvsdR3ia0a8QZ00aBVYdAzLoa0wXg/640?wx_fmt=png" alt=""></p>
<p>接下来，我们就从 Meta 公布的技术报告中，详细了解下 Llama 2。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qh2VTFSoUEr1hHVOR3AmQURRAthev8NUl7Xn8Ypro3fLIt16PA7GwBxw/640?wx_fmt=png" alt=""></p>
<ul>
<li>
<p>论文地址：https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</p>
</li>
<li>
<p>项目地址：https://github.com/facebookresearch/llama</p>
</li>
</ul>
<p>总的来说，作为一组经过预训练和微调的大语言模型（LLM），Llama 2 模型系列的参数规模从 70 亿到 700 亿不等。<strong>其中的 Llama 2-Chat 针对对话用例进行了专门优化。</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qh8BpRBfmJINOYnhpjTcohIqaY5LAuCU1rldb5wqNwKUM2AENODia5NsA/640?wx_fmt=png" alt=""></p>
<p><em>Llama 2-Chat 的训练 pipeline。</em></p>
<p>Llama 2 模型系列除了在大多数基准测试中优于开源模型之外，根据 Meta 对有用性和安全性的人工评估，它或许也是闭源模型的合适替代品。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qht62WZljOLAwibtW9Nia1vAHvzUycu714qQiaJLjg80oRUNQbE5kI3FNSw/640?wx_fmt=png" alt=""></p>
<p><em>Llama 2-Chat 与其他开源和闭源模型在安全性人类评估上的结果。</em></p>
<p>Meta 详细介绍了 Llama 2-Chat 的微调和安全改进方法，使社区可以在其工作基础上继续发展，为大语言模型的负责任发展做出贡献。</p>
<p><strong>预训练</strong></p>
<p>为了创建全新的 Llama 2 模型系列，Meta 以 Llama 1 论文中描述的预训练方法为基础，使用了优化的自回归 transformer，并做了一些改变以提升性能。</p>
<p>具体而言，Meta 执行了更稳健的数据清理，更新了混合数据，训练 token 总数增加了 40%，上下文长度翻倍。下表 1 比较了 Llama 2 与 Llama 1 的详细数据。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhicDrauDYP2umcMfpsrDT0Otm3rDbK7yPjdAibYJW6VN56tiarRBI3j5Lg/640?wx_fmt=png" alt=""></p>
<p>Llama 2 的训练语料库包含了来自公开可用资源的混合数据，并且不包括 Meta 产品或服务相关的数据。Llama 2 采用了 Llama 1 中的大部分预训练设置和模型架构，包括标准 Transformer 架构、使用 RMSNorm 的预归一化、SwiGLU 激活函数和旋转位置嵌入。</p>
<p>在超参数方面，Meta 使用 AdamW 优化器进行训练，其中 β_1 = 0.9，β_2 = 0.95，eps = 10^−5。同时使用余弦学习率计划（预热 2000 步），并将最终学习率衰减到了峰值学习率的 10%。</p>
<p>下图 5 为这些超参数设置下 Llama 2 的训练损失曲线。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qhy4hJFqtLicCq1gVzROqD2wN8wbWEgHC7pCfq2YwfhNdXs3Y2Rzytw0Q/640?wx_fmt=png" alt=""></p>
<p>在训练硬件方面，Meta 在其研究超级集群（Research Super Cluster, RSC）以及内部生产集群上对模型进行了预训练。两个集群均使用了 NVIDIA A100。</p>
<p>在预训练的碳足迹方面，Meta 根据以往的研究方法，利用 GPU 设备的功耗估算和碳效率，计算了 Llama 2 模型预训练所产生的碳排放量。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhrgHIOdjjWcS7u6oKzKtMZ4emA8rFnfOqNQtbkHNvux8WuCTfbK7wEA/640?wx_fmt=png" alt=""></p>
<p><em>预训练期间 Llama 2 各个模型的碳排放量。</em></p>
<p><strong>Llama 2 预训练模型评估</strong></p>
<p>Meta 报告了 Llama 1、Llama 2 基础模型、MPT（MosaicML）和 Falcon 等开源模型在标准学术基准上的结果。</p>
<p>下表 3 总结了这些模型在一系列流行基准上的整体性能，结果表明，Llama 2 优于 Llama 1 。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhlmuEdwAqvXbGV6UYz96j1lh8VEH80lxdJfosjvAjeLjaCgRGsO5lYA/640?wx_fmt=png" alt=""></p>
<p>除了开源模型之外，Meta 还将 Llama 2 70B 的结果与闭源模型进行了比较，结果如下表 4 所示。<strong>Llama 2 70B 在 MMLU 和 GSM8K 上接近 GPT-3.5，但在编码基准上存在显著差距。</strong></p>
<p>此外，<strong>在几乎所有基准上，Llama 2 70B 的结果均与谷歌 PaLM (540B) 持平或表现更好，不过与 GPT-4 和 PaLM-2-L 的性能仍存在较大差距。</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhPJByF5X432QVZicwf0aNkIvEy0AjicEAztgkPcaxBdJ47JgiaFsFeorIA/640?wx_fmt=png" alt=""></p>
<p><strong>微调</strong></p>
<p>Llama 2-Chat 是数个月研究和迭代应用对齐技术（包括指令调整和 RLHF）的成果，需要大量的计算和注释资源。</p>
<p><strong>监督微调 (SFT)</strong></p>
<p>第三方监督微调数据可从许多不同来源获得，但 Meta 发现其中许多数据的多样性和质量都不够高，尤其是在使 LLM 与对话式指令保持一致方面。因此，他们首先重点收集了几千个高质量 SFT 数据示例，如下表 5 所示。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qh3jahanRZxSSxseD4HSUYhic3GQYB90qZGjveJ2xjgGuq8YZVyTqfJhA/640?wx_fmt=png" alt=""></p>
<p>在微调过程中，每个样本都包括一个提示和一个回答。为确保模型序列长度得到正确填充，Meta 将训练集中的所有提示和答案连接起来。他们使用一个特殊的 token 来分隔提示和答案片段，利用自回归目标，将来自用户提示的 token 损失归零，因此只对答案 token 进行反向传播。最后对模型进行了 2 次微调。</p>
<p><strong>RLHF</strong></p>
<p>RLHF 是一种模型训练程序，适用于经过微调的语言模型，以进一步使模型行为与人类偏好和指令遵循相一致。Meta 收集了代表了人类偏好经验采样的数据，人类注释者可据此选择他们更喜欢的两种模型输出。这种人类反馈随后被用于训练奖励模型，该模型可学习人类注释者的偏好模式，然后自动做出偏好决定。</p>
<p>下表 6 报告了 Meta 长期以来收集到的奖励建模数据的统计结果，并将其与多个开源偏好数据集进行了对比。他们收集了超过 100 万个基于人类应用指定准则的二元比较的大型数据集，也就是元奖赏建模数据。</p>
<p>请注意，提示和答案中的标记数因文本领域而异。摘要和在线论坛数据的提示通常较长，而对话式的提示通常较短。与现有的开源数据集相比，本文的偏好数据具有更多的对话回合，平均长度也更长。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhntJRIUZdx1l46GDJz0l5xs0T2o08CNeE1MpSNGvJz2Zk5tv4AThKWw/640?wx_fmt=png" alt=""></p>
<p>奖励模型将模型响应及其相应的提示（包括前一轮的上下文）作为输入，并输出一个标量分数来表示模型生成的质量（例如有用性和安全性）。利用这种作为奖励的响应得分，Meta 在 RLHF 期间优化了 Llama 2-Chat，以更好地与人类偏好保持一致，并提高有用性和安全性。</p>
<p>在每一批用于奖励建模的人类偏好注释中，Meta 都拿出 1000 个样本作为测试集来评估模型，并将相应测试集的所有提示的集合分别称为「元有用性」和「元安全性」。</p>
<p>下表 7 中报告了准确率结果。不出所料，Meta 自己的奖励模型在基于 Llama 2-Chat 收集的内部测试集上表现最佳，其中「有用性」奖励模型在「元有用性」测试集上表现最佳，同样，「安全性」奖励模型在「元安全性」测试集上表现最佳。</p>
<p>总体而言，Meta 的奖励模型优于包括 GPT-4 在内的所有基线模型。有趣的是，尽管 GPT-4 没有经过直接训练，也没有专门针对这一奖励建模任务，但它的表现却优于其他非元奖励模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhhlsvoSgjUVP72jTMU15eU1t9kFfj2R9ueoEfjI5dh9TVHknVg9Efkg/640?wx_fmt=png" alt=""></p>
<p>缩放趋势。Meta 研究了奖励模型在数据和模型大小方面的缩放趋势，在每周收集的奖励模型数据量不断增加的情况下，对不同的模型大小进行了微调。下图 6 报告了这些趋势，显示了预期的结果，即在类似的数据量下，更大的模型能获得更高的性能。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhInqAaOWs8W4op34AIRIaLla8icWAZYeGYMeQ4Hl8QZwLOYiaicOL8Cyibw/640?wx_fmt=png" alt=""></p>
<p>随着收到更多批次的人类偏好数据注释，能够训练出更好的奖励模型并收集更多的提示。因此，Meta 训练了连续版本的 RLHF 模型，在此称为 RLHF-V1、&hellip;&hellip; , RLHF-V5。</p>
<p>此处使用两种主要算法对 RLHF 进行了微调：</p>
<ul>
<li>
<p>近端策略优化 (PPO)；</p>
</li>
<li>
<p>Rejection 采样微调。</p>
</li>
</ul>
<p><strong>RLHF 结果</strong></p>
<p>首先是基于模型的评估结果。下图 11 报告了不同 SFT 和 RLHF 版本在安全性和有用性方面的进展，其中通过 Meta 内部的安全性和有用性奖励模型进行评估。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhLzaTdEfQBFibkgopGLzAAUaQtyRy2cRexYkEiamSSkLWU3egTQicW5xng/640?wx_fmt=png" alt=""></p>
<p>再来看人类评估结果。如下图 12 所示，Llama 2-Chat 模型在单轮和多轮提示方面均显著优于开源模型。特别地，Llama 2-Chat 7B 在 60% 的提示上优于 MPT-7B-chat，Llama 2-Chat 34B 相对于同等大小的 Vicuna-33B 和 Falcon 40B，表现出了 75% 以上的整体胜率。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhL9zfILt3BoOLWgjMvk33A7ib9dbYuuQ2NVfav1TgsOpgr99eGH44lSQ/640?wx_fmt=png" alt=""></p>
<p>在这里，Meta 也指出了人工评估的一些局限性。</p>
<p>虽然结果表明 Llama 2-Chat 在人工评估方面与 ChatGPT 不相上下，但必须指出的是，人工评估存在一些局限性。</p>
<ul>
<li>
<p>按照学术和研究标准，本文拥有一个 4k 提示的大型提示集。但是，这并不包括这些模型在现实世界中的使用情况，而现实世界中的使用情况可能要多得多。</p>
</li>
<li>
<p>提示语的多样性可能是影响结果的另一个因素，例如本文提示集不包括任何编码或推理相关的提示。</p>
</li>
<li>
<p>本文只评估了多轮对话的最终生成。更有趣的评估方法可能是要求模型完成一项任务，并对模型在多轮对话中的整体体验进行评分。</p>
</li>
<li>
<p>人类对生成模型的评估本身就具有主观性和噪声性。因此，使用不同的提示集或不同的指令进行评估可能会产生不同的结果。</p>
</li>
</ul>
<p><strong>安全性</strong></p>
<p>该研究使用三个常用基准评估了 Llama 2 的安全性，针对三个关键维度：</p>
<ul>
<li>
<p>真实性，指语言模型是否会产生错误信息，采用 TruthfulQA 基准；</p>
</li>
<li>
<p>毒性，指语言模型是否会产生「有毒」、粗鲁、有害的内容，采用 ToxiGen 基准；</p>
</li>
<li>
<p>偏见，指语言模型是否会产生存在偏见的内容，采用 BOLD 基准。</p>
</li>
</ul>
<p><strong>预训练的安全性</strong></p>
<p>首先，预训练数据对模型来说非常重要。Meta 进行实验评估了预训练数据的安全性。</p>
<p>该研究使用在 ToxiGen 数据集上微调的 HateBERT 分类器来测量预训练语料库英文数据的「毒性」，具体结果如下图 13 所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhzgYUialf92WMLibpWMVepnoOLTypMgvDZDic6UNHpm0dvJeHnp5AQNMzw/640?wx_fmt=png" alt=""></p>
<p>为了分析偏见方面的问题，该研究统计分析了预训练语料库中的代词和身份相关术语及其占比，如下表 9 所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhaYicN2sib13NxPZ0CYtibhFwog49Taicj758E0sPaMUPhiaWuUx2Qk7tCJQ/640?wx_fmt=png" alt=""></p>
<p>此外，在语言分布方面，Llama 2 语料库涵盖的语种及其占比如下表 10 所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhPylSNKCKvAbXxXwHL2bmH5c0vuU6nByeWm85AjltubrgZGHBYNvP7A/640?wx_fmt=png" alt=""></p>
<p><strong>安全微调</strong></p>
<p>具体来说，Meta 在安全微调中使用了以下技术：1、监督安全微调；2、安全 RLHF；3、安全上下文蒸馏。</p>
<p>Meta 在 Llama 2-Chat 的开发初期就观察到，它能够在有监督的微调过程中从安全演示中有所总结。模型很快就学会了撰写详细的安全回复、解决安全问题、解释话题可能敏感的原因并提供更多有用信息。特别是，当模型输出安全回复时，它们往往比普通注释者写得更详细。因此，在只收集了几千个有监督的示范后，Meta 就完全改用 RLHF 来教模型如何写出更细致入微的回复。使用 RLHF 进行全面调整的另一个好处是，它可以使模型对越狱尝试更加鲁棒。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qh6gvPJib65tIH2nwsvg8u0N8ibzHjQ8BncXE94CLwPpVMvgUltBuIckuA/640?wx_fmt=png" alt=""></p>
<p>Meta 首先通过收集人类对安全性的偏好数据来进行 RLHF，其中注释者编写他们认为会引发不安全行为的 prompt，然后将多个模型响应与 prompt 进行比较，并根据一系列指南选择最安全的响应。接着使用人类偏好数据来训练安全奖励模型，并在 RLHF 阶段重用对抗性 prompt 以从模型中进行采样。</p>
<p>如下图 15 所示，Meta 使用平均奖励模型得分作为模型在安全性和有用性方面的表现结果。Meta 观察到，当他们增加安全数据的比例时，模型处理风险和对抗性 prompt 的性能显著提高。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhalzBqhC8g5y76M4wZHIJ6E7kjtnO4CDgKMVHQ4R780GOmWHcpvVf4Q/640?wx_fmt=png" alt=""></p>
<p>最后，Meta 通过上下文蒸馏完善了 RLHF 流程。这涉及到通过在 prompt 前加上安全前置 prompt 来生成更安全的模型响应，例如「你是一个安全且负责任的助手」，然后在没有前置 prompt 的情况下根据更安全的响应微调模型，这本质上是提取了安全前置 prompt（上下文）进入模型。</p>
<p>Meta 使用了有针对性的方法，允许安全奖励模型选择是否对每个样本使用上下文蒸馏。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhQBFNxJ29mEUg0W6Fy7j5RvAGLiby6lERGCricibt8qbuXic6EwJeXgvNgA/640?wx_fmt=png" alt=""></p>
<p>下图 17 展示了各种 LLM 的总体违规百分比和安全评级。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhQ9nSKmkdh12dxLhShsw6gaQVfJeNRH6XTA7HNcVhCn7QlvYC6yZw5Q/640?wx_fmt=png" alt=""></p>
<p>下图 18 展示了单轮和多轮对话的违规百分比。跨模型的一个趋势是，多轮对话更容易引发不安全的响应。也就是说，与基线相比，Llama 2-Chat 仍然表现良好，尤其是在多轮对话中。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhaIJE0Gmk9ibbic8L4hsNRv4Bm4W06N0jviag4ps7VD4NoLnfIYEMpxX4A/640?wx_fmt=png" alt=""></p>
<p>下图 19 显示了不同 LLM 在不同类别中安全违规百分比。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4Qh8cvib31pdVDlvAUVCwg5d9KK6sia7ibVdpBBTbcMnvYpfnvqAVyFmqbiaw/640?wx_fmt=png" alt=""><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8qNib90CicdCUscaqxAgH4QhZdyNM24ZXyYvyYk0EQ7uQLnNsVEHL7Pt0BDmdSob3XVmtkZBfkWMAg/640?wx_fmt=png" alt=""></p>
<p><em>参考链接：https://ai.meta.com/llama/</em></p>
<p>本文转自：机器之心</p>
<p>更多AI工具，参考<a href="https://aibard123.com/">Github-AiBard123</a>，<a href="https://aibard123.com/">国内AiBard123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


