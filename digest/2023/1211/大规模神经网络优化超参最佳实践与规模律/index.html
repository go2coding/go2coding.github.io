

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>大规模神经网络优化：超参最佳实践与规模律 作者： PaperWeekly 来源： PaperWeekly ©作者 | 郑奘巍 单位 | 新加坡国立大学 研究方向 | 高效机器学习与神经网络优化 从理论分析入手把握大规模神经网络优化的规律，可以指导实践中的超参数选择。反过来，实践中的超参数选择也可以指导理论分析。本篇文章聚焦于大语言模型，介绍从 GPT 以  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">大规模神经网络优化：超参最佳实践与规模律</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              December 11, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLkRm2xM6RibJGgJHRBzWOSjIcyI7ia7zQzKDicUaxnTUL30xzMNaEIlbHQ/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： PaperWeekly  来源： <a href="https://mp.weixin.qq.com/s/qETqjvApxnB73fEe4pr7_A">PaperWeekly</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDHKVtfYDubjKdZRUjAfBQQicXjoZWJ3qnK42ooD4eeJUfJBM4SSZVa2RE5lO0j6rWwzliby0j9u4bDg/640?wx_fmt=gif" alt=""></p>
<p><strong>©作者 |</strong> 郑奘巍</p>
<p><strong>单位 |</strong> 新加坡国立大学</p>
<p><strong>研究方向 |</strong> 高效机器学习与神经网络优化</p>
<p>从理论分析入手把握大规模神经网络优化的规律，可以指导实践中的超参数选择。反过来，实践中的超参数选择也可以指导理论分析。本篇文章聚焦于大语言模型，介绍从 GPT 以来大家普遍使用的训练超参数的变化。</p>
<p>规模律研究的是随着神经网络规模的增大，超参数、性能是如何改变的。规模律是对模型、数据、优化器关系的深刻刻画，揭示大模型优化时的普遍规律。通过规模律，我们可以用少量成本在小模型上验证超参数的选择和性能的变化情况，继而外推到大模型上。</p>
<p>在 LLM 中规模性常常变换模型大小和数据规模，进行大量调参而保持优化器不变。故对于大模型优化器而言，规模性是其性能很好的展现（性能上限）。设计更好的优化器（用更少的数据达到相同的性能）就是在挑战现有的规模律。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wulOVRfC18yCkd6xXqGq22h6QUk8chptF0fnQ4uXeZtAktYMrWwG2SyQ/640?wx_fmt=png" alt=""></p>
<p><strong>超参最佳实践</strong></p>
<p>我们首先回顾从 GPT 以来重要文章中使用的超参数，本文将不同模型的超参数列举在下方。首先，除了 Google 的 T5, PaLM 外，其它的模型都是用了 Adam 类的优化器（Adam 或 AdamW）。其次，超参数选择上的更新都是在前人的基础上慢慢变化，并被后续采纳的。这包括使用 dropuout、梯度范数裁剪（Megatron-LM），批量的动态变化（GPT-3），Adam （GPT-3）。</p>
<p><strong>学习率：</strong> 我们发现随着模型的增大，学习率越来越小。学习率与数据量、批量大小都没有明显的关系，且一般使用  左右的学习率。学习率的变化策略都包括 warmup 和衰减（decay）两阶段。目前普遍使用 GPT-3 中余弦衰减到原学习率的十分之一。谷歌则倾向于使用平方根衰减（优点之一在于不用提前知道训练步数）。</p>
<p><strong>批量大小：</strong> 训练使用的批量大小随着模型的增大也在不断增大，从 GPT 的 32k、BERT 的 128k，到 GPT-3 的 3.2M、LLaMA 的 4M。值得注意的是，GPT-3 的批量大小是从 32k 开始，在 12B tokens 的训练中逐渐增加到 4M 的，批量大小增加了 125 倍。</p>
<p>OpenAI 在论文中认为随着学习的进行，模型能够承载的批量大小快速增加。而后续很多工作直接使用了更大的批量。这可能是批量增大的过程只占总数据的 2%，即使直接使用最大批量也不会造成太大的问题。</p>
<p><strong>权重衰减 /L2 正则化：</strong> 在 L2 正则化（或 weight decay）上，GPT 与 BERT 都使用了正则化，后续的模型有些使用而有些没有使用。首先注意到，在 GPT 和 BERT 时代，数据量还是大于模型参数量的（over-parameterized），训练时也是使用多轮训练（multi-epoch）。</p>
<p>而随着人们意识到数据的重要性，数据量已经超越模型的参数量的（GPT3, 680B tokens, 175B params, under-parameterized），训练时也只使用了一轮训练（single-epoch）。根据 [ADV+23] 中的分析，在 over-parameterized 网络中使用 weight decay 相当于对优化器施加了潜在的正则；而在 under-parameterized 网络中，weight decay 只是改变了实际的学习率。随着网络训练权重的变化，相当于施加了自适应的学习率变化策略。</p>
<p>在本文的最后列举了不同模型的超参选择。其中 Adam 括号中的数字代表 ，sch 为学习率调整策略，bs为批量大小，L2 为权重衰减的  权重，init 为初始化方法。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wuhfgUpIfdPSqH8YjjHbCUiaaKsMA36bIMsMtGNKoBcus5py06M0fvx3A/640?wx_fmt=png" alt=""></p>
<p>####<strong>神经网络规模律</strong></p>
<p>神经网络规模律（neural scaling laws）通过廉价的小规模实验来预测大规模模型的表现，从而决定最佳的架构、算法、数据集、超参数等等。从广义上讲所有因素都可以研究：模型的宽度，数据数量，计算资源（FLOPs）等等。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLxpX8ttiamJvuXVb3YU1Wxau8Nv1cSOdvv9dVt5Iqibm51uVjwMibXVLqg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>上图是强化学习中的一些例子，黑色点为实验数据，红色线为拟合的规模律，绿色点为验证数据。可以看到，如果规模律的拟合效果好，就可以用来预测大规模模型的表现。除了上述单调的规模律，还有一些非单调的规模律，如下图所示。Tranformer 的性能随着模型的宽度增加先增加后减小最后再增加。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLZcNCVz1H15yfwXGzWMQJnq3Jmj2FaicE8yscUvlIerQEDbmGp94jBag/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>神经网络规模律的研究重点之一在于研究什么样的曲线能够拟合上述现象。一个简单的拟合策略是使用 ，这可以对付不少情况，然而无法应对上述非单调的情况。[CGR+23] 提出了自己的拟合曲线 BNSL（broken neural scaling laws）</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLI4wOFpCtLvPPtU0j0qUlJgzktcX3ibGvlaG90ExQT9icib2jvANolABeg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>其中  对应横坐标，其它参数为拟合参数。其中， 代表了曲线由  段组成，当  时就是 。大家不用纠结于公式的具体形式，该公式只是希望“大包大揽”，把所有可能的规模性都考虑进来。这个公式允许出现下图中所示的三种变化方式，具有很高的灵活性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLhRvy5ozyxN4P47BQjXRGp78oXaqkZMoIg0GVF4Wes029a1xEFibyv8g/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wukOjHSmSsEuRCB0fJu69CtdNgLnvFPDUCgeicOppBKuDvniaD3q8XWQ0Q/640?wx_fmt=png" alt=""></p>
<p>####<strong>大语言模型规模律</strong></p>
<p>讨论大语言模型规模律最重要的两篇可以说是 OpenAI 的 [KMH+20] 和 DeepMind 的 Chinchilla[HBM+22] 了。我们将主要介绍这两篇文章的结论。</p>
<p>定义  为模型参数量， 为数据量， 为计算量（FLOPs）， 为损失值。超参数分为优化超参数（学习率等）和架构超参数（如深度、宽度）。 为批量大小， 为训练步数，对于单轮训练，。其中对于大语言模型，确定  和  大小后，就可以估算出 。</p>
<p>实际中我们拥有的计算量为  时，为了获得最低的损失 ，我们希望通过选择  和  使得  最小。记  为给定计算量下最佳的 ，即</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLHLj0N3TRKK9Fok5TE2B5ESnw9Mdj6d9iaPEkiaC1bvxlffx2W0qQgjUw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>1. 模型性能与</strong>** 密切相关，与架构超参数关系不大。**</p>
<p><strong>2. L 与</strong>** 成幂律分布（Power-law），<strong><strong>即</strong></strong>****。**</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkL4wdojglFxR1yUlEibteDpdmxMcuEZOIfjymfibrRFcRCMsooAOILmfuA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>这里  指的是在给定  下的最佳性能，即最低的损失值。该规律的前提条件是不受另外两个因素制约。由于 ，该规律最终会失效，但 [KMH+22] 的实验规模使我们看不到这一点。</p>
<p><strong>3. 给定计算量后</strong>**，**** 。**</p>
<p>该结论即当模型参数翻倍后，数据量也应该翻倍从而得到最优性能。这是 [HBM+22] 中对 [KMH+20] 主要纠正的结论。下图中黑色虚线为 [KMH+20] 的结论，其它三色线是 [HBM+22] 用三个方法得出的相同结论，并且根据该放缩率训练了 Chinchilla 模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLNfF0xEQNvS4yPyvZ63TSqlzicJm16DMajR2maMgKadYpQibUSGMvAZfw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在 [KMH+20] 中，作者认为模型增大 5 倍，数据量增大 8 倍。[HBM+22] 认为两个因素导致了[KMH+20] 中的错误：</p>
<ul>
<li>
<p>对不同的  没有尝试使用不同的学习率调整策略（正确的学习率调整策略对训练影响很大）</p>
</li>
<li>
<p>[KMH+20] 使用的  较小。<strong>规模性存在曲率</strong> ，导致用太小的 得到的结论不准确。（规模性存在曲率也说明了最终该规律会失效）</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLkIRiaicfgUW3LtYcC3DNxpfChIXq4jQz01T7y3a3SBSzaJZ2LtdXwm5Q/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>这里展式 [HBM+20] 中的一种论证，即绘制相同  下不同  与最优  的关系，从而得到最优配置。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkL9hqrRBCibBhMgZrpOeCdpLqBJOIOiabaaoOTDkaQvkkU1VoUKzickJkLg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Chinchilla 规模律的最终拟合结果如下，通过代入  我们可以计算得到述  的取值，并可以揭示数据与模型规模应该同时增加的规律。此外，在 Chinchilla 的设置下，。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLNeAh8wKsOlTPJvrARIwYI5AE1LY8qTl7CDylXJgTotbiaou0zC9vm3g/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>4. 临界批量大小</strong>**，与其它因素弱相关。**</p>
<p>临界批量大小在大规模神经网络优化：批量与噪声中有过介绍，可以理解为使用相同  可以达到相同  的最大 。在 [KMH+20] 中，拟合得到 。 约小可以用的批量越大也解释了上文 GPT-3 模型中批量大小的增大。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLrKxVD7tnVosPvkK43SlLQlF1liczPLZcaNu3CVfPWdzpPIw1BDibhzAQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>另一方面，训练损失随着训练步数呈现快速下降-线性-平坦三个阶段的特点（见下图 Llama 训练图）。由于训练早期训练损失的快速下降，临界批量大小又随损失幂律下降，可见临界批量大小随训练步数下降的很快。我们用将 llama 的损失带入计算，当训练的非常前期损失就能下降到 2.2，临界批量大小 4.7M，这与 llama 使用的 4M 批量大小吻合。这也解释了为什么可以省略掉批量大小的调整。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLAWvBCeF7wANZKpQOHpnvvoPUMUkqiaApaa8SDTXXsoQK5XpCusZ3G6g/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>如果损失能够下降到 1.5，临界批量大小就会增加到 30M，所以 llama 可以在训练中进一步增加批量大小的使用。按此推断，GPT-4 最终使用了 60M 的批量大小，对应的训练损失可能为 1.3。</p>
<p>####<strong>5. 模型的迁移泛化能力与在训练数据集上的泛化能力正相关。</strong></p>
<p>如右图所示，在训练数据集上的测试损失越低，则在其它数据集上的损失也越低（如训练在 Wikipedia，测试在 WebText2）。右图则显示随着参数量增大，模型的测试损失越低。且在不同数据集上的测试损失与在训练集上的测试测试损失仅仅相差一个常数偏移。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLMsYtba1bXnic2J8gN2pgsX51QI2V6JPBy3Qg5Qs0695IVFIv4An7zBA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>####<strong>6. 更大的模型收敛更快（更少的数据量达到相同的损失）</strong></p>
<p>下图中越亮的线代表更大的模型。左图说明达到相同的测试损失，使用大模型需要见到的数据量更少。右图中则是使用相同计算量的比较。两条线的交点分割了使用大小模型的优劣：在交点左侧应该使用小模型，在交点右侧应该使用大模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLSj1N6kfVhOGoDffpzrhMr6FvaeySNFGvreFkJ8p7pQq935M3qesic2g/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图中另外一个重要的观察是，训练后期损失下降的更慢。故与其训练一个小模型到收敛，不如用相同的资源训练一个不到收敛的大模型更加高效。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wukOjHSmSsEuRCB0fJu69CtdNgLnvFPDUCgeicOppBKuDvniaD3q8XWQ0Q/640?wx_fmt=png" alt=""></p>
<p>####<strong>大语言模型规模律拾遗</strong></p>
<p>除了上述两篇经典文章之外，不少文章也给出了自己的洞见。</p>
<p>####<strong>3.1 涌现是指标选择的结果，连续指标与参数规模符合幂律分布</strong></p>
<p>涌现现象指的是模型的某些性能随着模型参数增加到一定规模突然不可预测的快速提升。这被认为是大模型能力的重要体现。这里我们研究的是指标性能与模型参数的关系，也是一种规模律。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLIRrhfI4PACRxbiadRBl4lQUyKxW94bdO0DF9cNKz2icyiajSzFl1h0RKg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>[SMK23] 论文则指出，大部分所谓的涌现现象，都出现在两种指标上：多选题的正确性，以及完全字符串匹配正确性。更换指标可以更好的对模型能力的规模性进行预测。</p>
<p>上文中我们已经知道，模型损失值随模型参数指数下降（图A），从而可以得到单个样本预测的正确率指数上升（图B）。如果将非线性指标“完全字符串匹配正确率”替换为“错误预测的 Token 数”，可以发现同样的幂律分布。同理，将不连续的选择正确率替换为连续的选择正确率，也可以得到幂律分布。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLkRm2xM6RibJGgJHRBzWOSjIcyI7ia7zQzKDicUaxnTUL30xzMNaEIlbHQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>笔者认为，这篇文章不应该看做对”涌现“重要性的否定。在现实世界、生活、市场中，我们关心的指标就是非线性，或者说非连续指标。这篇文章的意义在于，我们可以用连续指标更好的建模规模律，从而预测非连续指标的变化。同时，这也揭示了大模型中”量变产生质变“的背后机理，并不需要用“整体的复杂交互”进行解释。</p>
<p>####<strong>3.2 大模型需要更小的学习率</strong></p>
<h4 id="通过上文中的大模型参数经验我们很容易就发现大模型需要更小的学习率yhb22-在下左图中展示了这点其认为这是为了控制总方差在一定值方差随参数量以--增大对于这点笔者暂未找到详细的理论解释yhb22-中还提出了一种新的初始化和参数设置方法以保证不同规模的模型可以使用相同的学习率这里不再展开">通过上文中的大模型参数经验，我们很容易就发现大模型需要更小的学习率。[YHB+22] 在下左图中展示了这点。其认为这是为了控制总方差在一定值（方差随参数量以  增大）。对于这点笔者暂未找到详细的理论解释。[YHB+22] 中还提出了一种新的初始化和参数设置方法以保证不同规模的模型可以使用相同的学习率，这里不再展开。</h4>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkL5zf0mKic6PXBC7ScUYNibMM51XficD8edZFfictbgoXDMApw8UTyzaq4vQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>####<strong>3.3 使用重复数据训练时（multi-epoch），应该用更多的轮次训练较小的模型</strong></p>
<p>[MRB+23] 探究了当数据有限时，如何训练大模型。左图中，当轮次小于 4 时，与使用新数据效果相当（GPT-4 中重复了文本两次，代码四次，与该结果印证）。当轮次大于 40 次时，则几乎没有提升。右图中，用左图的拟合结果可以计算得到，相比于 Chinchilla 的规模性，使用重复数据训练时，应该用更多的数据（重复数）训练较小的模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLzibkJPnFAfyUq1KYSURMZkNDMib1AqDqvVEkoFtyGnUxNZB1PkuALJrQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>####<strong>3.4 使用重复数据训练对训练帮助很小</strong></p>
<p>[XFZ+23] 进行了大量的实验验证了一系列观点。下左图中，作者在 Encoder-Decoder 模型上验证了 Chinchilla 规模律同样成立（即数据量与模型参数量应该同时增加）。右图则显示了使用出发数据训练对性能没有帮助。文中还尝试了高质量数据、UL2 训练目标、不同的正则化方法，最终发现除了 Dropout 之外对重复训练都没有帮助。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLalLrdhkbJZHBNLh3pW1k57XicSdcgfetySk7RzsN1CtVb8hiciabv7Qqw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>####<strong>3.5 训练比 Chinchilla 规模律更小的模型</strong></p>
<p>Chinchilla 规模律的出发点是给定计算量，通过分配参数量和数据量最小化损失值。换言之，给定要达到的损失值，最小化计算量。然而在实际中，训练一个小模型能带来计算量（代表训练开销）以外的收益：</p>
<ul>
<li>
<p>小模型部署后进行推理成本更小</p>
</li>
<li>
<p>小模型训练所需的集群数量更少</p>
</li>
</ul>
<p>故 [H23] 提出，在不大幅度增加训练开销的前提下，尽可能减小模型的参数量。具体而言，作者在 Chinchilla 规模律的基础上，让模型的参数量变为 ，进而计算出达到相同损失所需的数据量 。通过推导可得  与  无关，即无论训练开销多大， 与  的关系都是一致的。下图展示了计算量的增加值  与  的关系。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLPGtYf3ariaKPAJnlN36j8ToICwFEcFYeR5c5g23sqbwZ56vWorUbWibA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>其中，LLaMA-7B 就比 Chinchilla 中对应的最优解使用了更小的模型和更多的计算量（数据）。由于参数量减小到一定程度，需要的计算量会有急剧的上升，作者认为模型的大小不应该小于临界模型大小。譬如当使用 30% 的参数量时，所需计算量会增加 100%。参数量不应该再继续减小（否则计算量会上升很多）。</p>
<p>在 Llama-2 上我们也能看到类似的现象。根据 Chinchilla 规模性，2T 数据对应大约 50B 的参数量。所以对于 Llama-2-7b 来说，训练了一个相对更小的模型。而对于 Llama-2-70b 来说，则不够效率。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLr7BrZIkibbpAaNziciczbQAv75UomQTNvPZbTT2ia2as2FV0awFfDicqasA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>Werra 认为我们应该用更多的数据继续训练更小的模型。这其中的难点在于：</p>
<ul>
<li>
<p>训练所需的数据量不够（正如 [XFZ+23] 指出的，我们正在用尽互联网上所有的 tokens）。</p>
</li>
<li>
<p>小集群上训练小模型需要更长的训练时间（Llama2 500k its）；如果使用大集群训练则更困难（比如要使用更大的批量大小才能提高效率）。</p>
</li>
</ul>
<h4 id="heading"></h4>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wuiaLfO9V4lkD8cXK7ImEicqib5bPGH6syOrWzicR2KaqPyAicMccs8icC03Gw/640?wx_fmt=png" alt=""></p>
<p>####<strong>LLM 的超参选择</strong></p>
<p><strong>4.1 GPT</strong> （117M）：</p>
<ul>
<li>
<p>Adam</p>
</li>
<li>
<p>lr：2.5e-4</p>
</li>
<li>
<p>sch: warmup linear 2k, cosine decay to 0</p>
</li>
<li>
<p>bs: 32k=64x512</p>
</li>
<li>
<p>its: 3M (100e)</p>
</li>
<li>
<p>L2: 0.01</p>
</li>
<li>
<p>init: N(0, 0.02)</p>
</li>
</ul>
<p><strong>4.2 BERT</strong> （330M）：</p>
<ul>
<li>
<p>Adam(0.9,0.999)</p>
</li>
<li>
<p>lr: 1e-4</p>
</li>
<li>
<p>sch: warmup 10k, linear decay to 0</p>
</li>
<li>
<p>bs: 128k=256x512</p>
</li>
<li>
<p>its: 1M (40e)</p>
</li>
<li>
<p>L2: 0.01</p>
</li>
<li>
<p>dropout: 0.1</p>
</li>
</ul>
<p><strong>4.3 Megatron-LM</strong> （GPT2 8.3B &amp; Bert 3.9B）：</p>
<ul>
<li>
<p>Adam</p>
</li>
<li>
<p>lr: 1.5e-4</p>
</li>
<li>
<p>sch: warmup 2k, cosine decay to 1e-5</p>
</li>
<li>
<p>bs: 512k=512x1024</p>
</li>
<li>
<p>its: 300k</p>
</li>
<li>
<p>L2: 0.01</p>
</li>
<li>
<p>dropout: 0.1</p>
</li>
<li>
<p>gradient norm clipping: 1.0</p>
</li>
</ul>
<p>init: N（0, 0.02）, weights before residual layer</p>
<p><strong>4.4 T5 (11B)</strong></p>
<ul>
<li>
<p>AdaFactor</p>
</li>
<li>
<p>lr: 1e-2</p>
</li>
<li>
<p>sch: warmup constant 10k, sqrt decay</p>
</li>
<li>
<p>bs: 65k=128x512</p>
</li>
<li>
<p>its: 500k (1e)</p>
</li>
</ul>
<p><strong>4.5 GPT-3</strong></p>
<ul>
<li>
<p>Adam(0.9, 0.95, eps=1e-8)</p>
</li>
<li>
<p>lr &amp; final bs:‍</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLftjlF5qhUj4Qq8ODWJovibkpWRAYCWblicIKlAxUrzmH07jxkNWIZuSw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<ul>
<li>
<p>sch: warmup linear 375m tokens, cosine decay to 0.1xlr 260b tokens, continue training with 0.1xlr</p>
</li>
<li>
<p>bs sch: 32k to final bs gradually in 4-12B tokens</p>
</li>
<li>
<p>seq length: 2048</p>
</li>
<li>
<p>data: 680B</p>
</li>
<li>
<p>gradient norm clipping: 1.0</p>
</li>
</ul>
<p><strong>4.6 Gopher</strong></p>
<ul>
<li>
<p>Adam (Adafactor unstable beyond 7.1B)</p>
</li>
<li>
<p>lr &amp; final bs:‍</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLfy23gPFERnhWDHKFjmjL6DlicU8Aw03bursCM3IncUBicgblSa1msoHw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<ul>
<li>
<p>sch: warmup 1.5k, cosine decay to 0.1xlr</p>
</li>
<li>
<p>gradient norm clipping: 0.25 for 7.1B &amp; 280B, 1.0 for the rest</p>
</li>
</ul>
<p><strong>4.7 Chinchilla (70B)</strong></p>
<ul>
<li>
<p>AdamW</p>
</li>
<li>
<p>lr: 1e-4</p>
</li>
<li>
<p>bs: 1.5M to 3M</p>
</li>
<li>
<p>others follow Gopher</p>
</li>
</ul>
<p><strong>4.8 OPT</strong></p>
<ul>
<li>
<p>Adam(0.9, 0.95) (SGD plateau quickly)</p>
</li>
<li>
<p>lr &amp; bs:‍</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLOm4NNJiaXf5pV4ZKFaSg37XeHHcsE8XzO7t8sRgqTfFXRjgLicHeL71w/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<ul>
<li>
<p>sch: warmup linear 2k, decay to 0.1xlr</p>
</li>
<li>
<p>L2: 0.1</p>
</li>
<li>
<p>dropout: 0.1</p>
</li>
<li>
<p>gradient norm clipping: 1.0</p>
</li>
<li>
<p>init: N(0, 0.006), output layer N(0, 0.006* ）</p>
</li>
</ul>
<p><strong>4.9 PaLM</strong></p>
<ul>
<li>
<p>Adafactor(0.9, 1-)</p>
</li>
<li>
<p>lr 1e-2</p>
</li>
</ul>
<p>sch: warmup 10k, decay at</p>
<p>‍</p>
<ul>
<li>bs: 1M (&lt;50k), 2M (&lt;115k), 4M (&lt;255k)</li>
</ul>
<p>L2: lr</p>
<ul>
<li>
<p>dropout: 0.1</p>
</li>
<li>
<p>gradient norm clipping: 1.0</p>
</li>
<li>
<p>its: 255k‍init: N(0, embedding N(0,1)</p>
</li>
</ul>
<p><strong>4.10 LLaMA (RMSNorm, SwiGLU, RoPE)</strong></p>
<ul>
<li>
<p>AdamW(0.9, 0.95)</p>
</li>
<li>
<p>lr &amp; bs:</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLtPczZ6Mc3nOaamibnB7iaGooGFLTxoOpAQmYKics94d5ldcZiaeXrfaShA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<ul>
<li>
<p>sch: warmup 2k, decay to 0.1xlr</p>
</li>
<li>
<p>L2: 0.1</p>
</li>
<li>
<p>gradient norm clipping: 1.0</p>
</li>
</ul>
<p><strong>4.11 LLaMA2</strong></p>
<ul>
<li>
<p>AdamW(0.9, 0.95, eps=1e-5)</p>
</li>
<li>
<p>lr‍</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLdlWwMvBt5LhuxXhHMMT6DjeHbiatfDwAdY7bn2CNBibfTIFU79kqRthw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<ul>
<li>
<p>sch: warmup 2k, decay to 0.1xlr</p>
</li>
<li>
<p>L2: 0.1</p>
</li>
<li>
<p>gradient norm clipping: 1.0</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_svg/lpHDr05YrITiah4YpYUhEV6136AJO6TlsGReic1y9B6JHTbc6FnVRbQwMhhJZh7mxXCCSGFJR1bGravlfxQJibPWnTNO2gB11MQ/640?wx_fmt=svg&amp;from=appmsg" alt=""></p>
<p><strong>参考文献</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_svg/lpHDr05YrITiah4YpYUhEV6136AJO6TlsGReic1y9B6JHTbc6FnVRbQwMhhJZh7mxXCCSGFJR1bGravlfxQJibPWnTNO2gB11MQ/640?wx_fmt=svg&amp;from=appmsg" alt=""></p>
<p>[ADV+23] Why do we need weight decay in modern deep learning?<br>
[CGR+23] Broken neural scaling laws<br>
[HBM+22] Training Compute-Optimal Large Language Models<br>
[KMH+20] Scaling Laws for Neural Language Models<br>
[SMK23] Are Emergent Abilities of Large Language Models a Mirage?<br>
[YHB+22] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer<br>
[MRB+23] Scaling Data-Constrained Language Models<br>
[XFZ+23] To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis<br>
[H23] Go smol or go home</p>
<p><strong>更多阅读</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLj3TicTnxSNbLMVVKia4XPRkYKe2NQjXj6a91ao92zRNJxm8bt363YjXg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLxHkhsUAu2WEqZpOJA5OX99fH2p9LwJVOKwk0dtzs4VOyft1dQCDWEg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGgBdeDpEy3vzNUmE99YRkLjmLCiaRCPf9AVvKLmEcNfBMTtgoIayCYNa2yPv1wFaRCdc310w0spAQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDHHMXQ2IicFvJwssWxgWhKuK7ulQVyw7gPTxZia00vCxia2vzhRH6pGq8t1FN1zY48ibULAEZpic41k6eg/640?wx_fmt=gif" alt=""></p>
<p><strong>#投 稿 通 道#</strong></p>
<p>** 让你的文字被更多人看到**</p>
<p>如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？<strong>答案就是：你不认识的人。</strong></p>
<p>总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。</p>
<p>PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是<strong>最新论文解读</strong> ，也可以是<strong>学术热点剖析</strong> 、<strong>科研心得</strong> 或<strong>竞赛经验讲解</strong> 等。我们的目的只有一个，让知识真正流动起来。</p>
<p>📝<strong>稿件基本要求：</strong></p>
<p>• 文章确系个人<strong>原创作品</strong> ，未曾在公开渠道发表，如为其他平台已发表或待发表的文章，请明确标注</p>
<p>• 稿件建议以<strong>markdown</strong>  格式撰写，文中配图以附件形式发送，要求图片清晰，无版权问题</p>
<p>• PaperWeekly 尊重原作者署名权，并将为每篇被采纳的原创首发稿件，提供<strong>业内具有竞争力稿酬</strong> ，具体依据文章阅读量和文章质量阶梯制结算</p>
<p>📬<strong>投稿通道：</strong></p>
<p>• 投稿邮箱：hr@paperweekly.site</p>
<p>• 来稿请备注即时联系方式（微信），以便我们在稿件选用的第一时间联系作者</p>
<p>• 您也可以直接添加小编微信（<strong>pwbot02</strong> ）快速投稿，备注：姓名-投稿</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmic1CRCSOKfDibC3dZ4BaJuYyYTWJyw8gFxqon34STk3icf9aJbY4rqMpmhNjTGJXIGGFsCdTBHy3Tw/640?wx_fmt=png" alt=""></p>
<p><strong>△长按添加PaperWeekly小编</strong></p>
<p>🔍</p>
<p>现在，在**「知乎」** 也能找到我们了</p>
<p>进入知乎首页搜索**「PaperWeekly」**</p>
<p>点击**「关注」** 订阅我们的专栏吧</p>
<p>·</p>
<p>·</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnZ3nlEAOI3MyTd7jqeD6cq8uTbkM2xZNpribyNr9liaPJ722zaHxd0YpQvib2nxOYmWibydCVY7W94ew/640?wx_fmt=jpeg" alt=""></p>
<p>更多AI工具，参考<a href="https://aibard123.com/">Github-AiBard123</a>，<a href="https://aibard123.com/">国内AiBard123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


