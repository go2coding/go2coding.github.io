

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>不到1000行代码，PyTorch团队让Llama7B提速10倍 作者： 数据派THU 来源： 数据派THU 来源：机器之心 本文**约2300字** ，建议阅读**5****分钟** PyTorch 团队亲自教你如何加速大模型推理。 在过去的一年里，生成式 AI 发展迅猛，在这当中，文本生成一直是一个特别受欢迎的领域，很多开源项目如 lla  | AiBard123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AiBard123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://aibard123.com/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://aibard123.com/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AiBard123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AiBard123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">不到1000行代码，PyTorch团队让Llama7B提速10倍</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://aibard123.com/about>AiBard123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              December 11, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkK3gUvG6lrnHyshWTqDfIHFbaymOfxta4icEtzh6CKq5cDenZl25cJTg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： 数据派THU  来源： <a href="https://mp.weixin.qq.com/s/wiDugLaD23ii4TQdDJg1hg">数据派THU</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMmbq1qLbfTGuk3jmOPpGT7D5XWia0mA8twb2poibaBnypJvy5dMj7FGbQAjz6ic69NSHthvJ7jQqgz2g/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<pre><code>来源：机器之心













本文**约2300字** ，建议阅读**5****分钟** 

PyTorch 团队亲自教你如何加速大模型推理。
</code></pre>
<p>在过去的一年里，生成式 AI 发展迅猛，在这当中，文本生成一直是一个特别受欢迎的领域，很多开源项目如 llama.cpp、vLLM 、 MLC-LLM 等，为了取得更好的效果，都在进行不停的优化。</p>
<p>作为机器学习社区中最受欢迎框架之一的 PyTorch，自然也是抓住了这一新的机遇，不断优化。为此让大家更好的了解这些创新，PyTorch 团队专门设置了系列博客，重点介绍如何使用纯原生 PyTorch 加速生成式 AI 模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpknQUPj8VAQs1JQwluia6wWvcyQm4JvR4ib07xSOZcTehHa9gm5npSCHzw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>代码地址：https://github.com/pytorch-labs/gpt-fast</p>
<p>在第一篇博客中，PyTorch 团队展示了仅使用<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650897947&amp;idx=3&amp;sn=27da2fd05194f27bc8033c616174ece4&amp;chksm=84e4ba65b393337371a846afe432131299e488e364664d1ba13b53a2b8c464036d65946a91f6&amp;scene=21#wechat_redirect">纯原生 PyTorch 重写 Segment Anything（SAM）模型，比原始实现快 8 倍</a>。在本博客中，他们又为我们带来了新的内容，即如何加快 LLM 推理。</p>
<p>我们先来看看结果，该团队重写 LLM，推理速度比基线足足快了 10 倍，并且没有损失准确率，只用了不到 1000 行的纯原生 PyTorch 代码！</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkUbJDa7ic4ujt1petA9ZP8ia51QceNtg0LWica99wpsFOjBfACdSvfnHtg/640?wx_fmt=gif&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="">所有基准测试都在 A100-80GB 上运行的，功率限制在 330W。</p>
<p>这些优化包括：</p>
<ul>
<li>
<p>Torch.compile：PyTorch 模型编译器， PyTorch 2.0 加入了一个新的函数，叫做 torch.compile ()，能够通过一行代码对已有的模型进行加速；</p>
</li>
<li>
<p>GPU 量化：通过降低运算精度来加速模型；</p>
</li>
<li>
<p>Speculative Decoding：一种大模型推理加速方法，使用一个小的「draft」模型来预测大的「目标」模型的输出；</p>
</li>
<li>
<p>张量并行：通过在多个设备上运行模型来加速模型推理。</p>
</li>
</ul>
<p>接下来，我们看看每一步都是如何实现的。</p>
<p><strong>6 步加快大模型推理</strong></p>
<p>该研究表示，在没有优化之前，大模型的推理性能为 25.5 tok/s，效果不是很好：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkdxPAiaU4KJ7NopxzkLiclGgWiajzB1g01zVUtATL7iaP9ykjgOy1d0yAFQ/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>经过一番探索后终于找到了原因：CPU 开销过大。然后就有了下面的 6 步优化过程。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkmH5qkxmrvia0PdOzogQm7noEicaYwghwEhTyJvgNOrzXR4zrGpNZicvZg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>第一步：通过 Torch.compile 和静态 KV 缓存减少 CPU 开销，实现 107.0 TOK/S</strong></p>
<p>torch.compile 允许用户将更大的区域捕获到单个编译区域中，特别是在 mode=”reduce-overhead” 时（参考下面的代码），这一功能对于减少 CPU 开销非常有效，除此以外，本文还指定 fullgraph=True，用来验证模型中没有「图形中断」（即 torch.compile 无法编译的部分）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkLzkFibKmeaFI3d1rdQzicWoNUwKxVvg6T83A8W1aTkLo66Xricy6JEgrg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>然而，即使有 torch.compile 的加持，还是会遇到一些障碍。</p>
<p>第一个障碍是 kv 缓存。即当用户生成更多的 token 时， kv 缓存的「逻辑长度（logical length）」会增长。出现这种问题有两个原因：一是每次缓存增长时重新分配（和复制）kv 缓存的成本非常高；其次，这种动态分配使得减少开销变得更加困难。</p>
<p>为了解决这个问题，本文使用静态 KV 缓存，静态分配 KV 缓存的大小，然后屏蔽掉注意力机制中未使用的值。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkZst2rwnfG8eicLHWt4grKtBIB4zWvttx7YWfe57ZUeQpjsTdFJIsctA/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>第二个障碍是 prefill 阶段。用 Transformer 进行文本生成可视为一个两阶段过程：1. 用来处理整个提示的 prefill 阶段 2. 解码 token.</p>
<p>尽管 kv 缓存被设置为静态化，但由于提示长度可变 ，prefill 阶段仍然需要更多的动态性。因此，需要使用单独的编译策略来编译这两个阶段。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkcYvGiamsJfWncbcANLjTiaQAzcMslm6peCaneMTgUxDiaTKLbzEkV7LFg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>虽然这些细节有点棘手，但实现起来并不困难，而且性能的提升是巨大的。这一通操作下来，性能提高了 4 倍多，从 25 tok/s 提高到 107 tok/s。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkBUz6cAhD41vYvl9Ig6zccsLeolDZgibg1x9LT7pUDUicQKqibczHh1MGA/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>第二步：通过 int8 权重量化缓解内存带宽瓶颈，实现 157.4 tok /s</strong></p>
<p>通过上文，我们已经看到应用 torch.compile 、静态 kv 缓存等带来的巨大加速，但 PyTorch 团队并不满足于此，他们又找了其他角度进行优化。</p>
<p>他们认为加速生成式 AI 训练的最大瓶颈是将权重从 GPU 全局内存加载到寄存器的代价。换句话说，每次前向传播都需要「接触（touch）」GPU 上的每个参数。那么，理论上我们能够以多快的速度「接触」模型中的每个参数？</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpk3IFUR2ObOYIYdIZEGJnyic7sP20OGYtP0I3xQ8DZrWZZXlxX52xjP2g/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>为了衡量这一点，本文使用模型带宽利用率（MBU），计算它非常简单，如下所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkqfPBwFOBBluP306EG7YvSfUia8C4rVVDH1zB9KGyPfE65ibIxddnibPSg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>举例来说，对于一个 7B 参数模型，每个参数都存储在 fp16 中（每个参数 2 字节），可以实现 107 tokens/s。A100-80GB 理论上有 2 TB/s 的内存带宽。</p>
<p>如下图所示，将上述公式带入具体的数值，可以得到 MBU 为 72%！这个结果是相当不错的，因为很多研究很难突破 85%。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpk6jaKkKCVbndrfGx4DicS6V6qcciaViahBVoAS7ibMRnP1KiaHzia7VjiaGjPg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>但 PyTorch 团队还想将这个数值在提高一些。他们发现无法改变模型中参数的数量，也无法改变 GPU 的内存带宽。但他们发现可以更改每个参数存储的字节数！</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpk4sPjiagpnCG05gd4BQuu0k4ZGvibAQ8DFAQ6tFa8oHZWOG6d9rvU675g/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>因此，他们打算用 int8 量化。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkK3gUvG6lrnHyshWTqDfIHFbaymOfxta4icEtzh6CKq5cDenZl25cJTg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>请注意，这仅是量化权重，计算本身仍然在 bf16 中完成。此外，有了 torch.compile，可以轻松生成 int8 量化的高效代码。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkbWXgNQibKxFxCvKicgSrqR1UOZtBS5qRw2zAbQibDHeuvzjwcvKJNEZzw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkIia8WnibXM3dESuVrHA3oa8AHzAVdY3kqemtjDOP0Rdr86DmPV5bu9Og/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>就像上图所展示的，从深蓝色线（torch.compile + int8）可以看出，使用 torch.compile + int8 仅权重量化时，性能有显着提升。</p>
<p>将 int8 量化应用于 Llama-7B 模型，性能提高了约 50%，达到 157.4 tokens/s。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpk91oDaVkaw8OBj5XR1xdiaebAIIL29NBtyktXlxjvnvibOPhDtcqPnYcQ/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>第三步：使用 Speculative Decoding</strong></p>
<p>即使在使用了 int8 量化等技术之后，该团队仍然面临着另一个问题，即为了生成 100 个 token，必须加载权重 100 次。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpk6F4bwr8CEAW8cAubTZ5koktT9lM29ibAkUpibJW7VDqzy2TnSZYMx4ew/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>即使权重被量化，一遍又一遍地加载权重也避免不了，这种问题该如何解决呢？事实证明，利用 speculative decoding 能够打破这种严格的串行依赖性并获得加速。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkJS9dyL3ujGOZ4MXLrrkQWIXyeeZrdRxdGOM2fGJaMka9L6z6iazsNbw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>该研究使用草稿（draft）模型生成 8 个 token，然后使用验证器模型并行处理，丢弃不匹配的 token。这一过程打破了串行依赖。整个实现过程大约 50 行原生 PyTorch 代码。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkzH1C50zN4pMz4S5nfGhYhJzTmXKLThmZtZlOpE6vF7MhXTU2dmkB4Q/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>第四步：使用 int4 量化和 GPTQ 方法进一步减小权重，实现 202.1 tok/s</strong></p>
<p>本文发现，当权重为 4-bits 时，模型的准确率开始下降。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpktPZ5PFrCxQlTcuywCbAI4JFSIqHq5OcAvs8iaBqPX5jOxYydARBLq4Q/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>为了解决这个问题，本文使用两个技巧来解决：第一个是拥有更细粒度的缩放因子；另一种是使用更先进的量化策略。将这些操作组合在一起，得到如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkrljia3qhW4zB0GvxHphWqHAMnN4wibhzcib99aR1icCfe2o14ecXBOvmrw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>第五步：将所有内容组合在一起，得到 244.7 tok/s</strong></p>
<p>最后，将所有技术组合在一起以获得更好的性能，得到 244.7 tok/s。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkyxxBYpttlHoGPkFcQXeWRDytJicf5erQEMOF4Uf1XhNcz5gxW1ywtaA/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>第六步：张量并行性</strong></p>
<p>到目前为止，本文一直是在单个 GPU 上最大限度地减少延迟。其实，使用多个 GPU 也是可以的，这样一来，延迟现象会得到进一步改善。</p>
<p>非常庆幸的是，PyTorch 团队提供了张量并行的低级工具，只需 150 行代码，并且不需要任何模型更改。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpkibiaRicDsbuLfG7QqhOIxia8sqheEsKRZJbY22MylY9JBwolkxD3lXatQg/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>前面提到的所有优化都可以继续与张量并行性组合，将这些组合在一起，能以 55 tokens/s 的速度为 Llama-70B 模型提供 int8 量化。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicMHVsbuyPdwpbIWnWIfmpka9CrmX8Aped4HykaYTOrm3z2BPY0q6QzBJPRpuajkUUKaqVtlJy2zw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>最后，简单总结一下文章主要内容。在 Llama-7B 上，本文使用「compile + int4 quant + speculative decoding」这一套组合拳，实现 240+ tok/s。在 Llama-70B，本文还通过引入张量并行性以达到约 80 tok/s，这些都接近或超过 SOTA 性能。</p>
<p>原文链接：https://pytorch.org/blog/accelerating-generative-ai-2/</p>
<p>编辑：文婧</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMl9XjaZU7CpIkx0kf38xWc7KHZ5EMoTiaWXGbLUq5TTibJtBaa9I5wx1t3ASgD7sCEldTWET95jmYhA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>更多AI工具，参考<a href="https://aibard123.com/">Github-AiBard123</a>，<a href="https://aibard123.com/">国内AiBard123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


